---
title: "笔记：Computer Architecture A Quantatative Approach（更新到第2章）"
date: 2023-03-23T21:00:00+08:00
draft: true
tags: ["教程", "读书笔记"]
isCJKLanguage: true
---

- [Computer architecture: a quantitative approach](#computer-architecture-a-quantitative-approach)
    - [ch 1 Fundamentals](#ch-1-fundamentals)
    - [ch 2/B Memory Hierarchy Design](#ch-2b-memory-hierarchy-design)
        - [基础知识](#基础知识)
        - [cache 性能优化](#cache-性能优化)
        - [虚拟存储](#虚拟存储)
        - [virtual machine](#virtual-machine)
        - [Fallacy](#fallacy)
        - [Pitfall](#pitfall)
    - [ch 3/C Instruction-Level Parallelism and Its Exploitation](#ch-3c-instruction-level-parallelism-and-its-exploitation)
    - [ch A Instruction Set Principles](#ch-a-instruction-set-principles)
        - [ISA 特性](#isa-特性)
        - [编译器优化](#编译器优化)
        - [ISA 统计和对应的 RISC-V 设计](#isa-统计和对应的-risc-v-设计)
        - [Fallacy](#fallacy-1)
        - [Pitfall](#pitfall-1)


# Computer architecture: a quantitative approach

## ch 1 Fundamentals

- Internet of Things/Embedded Computers：缺乏量化基准
- Personal Mobile Device：soft real time（对实时性的要求），功耗优化
- Desktop Computing：性价比
- Servers：可用性，可拓展性，有效吞吐
- Warehouse：性价比，功耗

## ch 2/B Memory Hierarchy Design

### 基础知识

cache 基本配置有

1. block 可放置位置
   1. direct mapped：直接映射，$(Block\ Address)\mod(Number\ of\ blocks)$
   2. fully associative：全相联，cache 中任意位置
   3. set associative：组相联，在对应组中的任意位置，$(Block\ Address)\mod(Number\ of\ sets)$
2. 替换算法
   1. random：效果不差，但是缺乏确定性，对程序优化不友好
   2. FIFO：first-in-first-out，可能导致抖动
   3. LRU：Least recently used，较优，但算法复杂，一般采用简化版，如 clock 算法
3. 写策略

   - 写命中 cache 时候
     1. write through：写穿透，cache 和底层都写，保持一致性容易
     2. write back：写回，只写 cache，之后 cache 写回底层，性能较好
   - 写不命中时候，常常使用`write buffer`减少写带来的 stall
     1. write allocate：写分配
     2. No-write allocate：写不分配

### cache 性能优化

优化目标为平均访问时间，有

$$
\mathrm{Average\ memory\ access\ time}=\mathrm{Hit\ time} + \mathrm{Miss\ rate}\times \mathrm{Miss\ penalty}
$$

当中，可以把 miss 分类有

1. compulsory miss：第一次访存必然 miss
2. capacity miss：cache 容量有限，一些 block 被丢弃后再被访问
3. conflict miss：cache 不是全相联，set 满而部分 block 被丢弃后再被访问
4. coherence miss：多核时候，其他核修改导致数据过时而失效

简单优化有

1. 增大 block ，减少 miss rate
   - 利用 spacial locality：空间局部性，可以减少 compulsory miss
   - 可能增大 miss penalty
   - 在 cache 大小固定时候，过大的 block 大小会增加 conflict miss
2. 增大 cache ，减少 miss rate
   - 可能增加 hit time
   - 可能增加成本和功耗
3. 增加关联度
   - 比较电路设计麻烦，可能提高 hit time
   - 8-way 组相联和全相联一般表现类似
   - > 2:1 cache rule of thumb
     >
     > 大小 N 的 direct mapped 和$\frac{N}{2}$的 2-way set associative 一般 miss rate 相似（经验公式）
   - 可能增加 hit time，高关联性会要求更低的时钟频率
4. 多级 cache
   - multilevel inclusion/ multilevel exclusion
   - 平衡 fast hit 和 few misses
5. read miss 优先于 write miss， 减少 miss penalty
   - read miss 一般和取指，取数计算有关，优先可以减少程序的 stall
   - 写缓存可能导致数据不一致，等写回内存用时过长
6. 在 cache 内索引时避开地址翻译， 降低 hit time
   - VIVT 对于保护,重名不利
   - VIPT 需要如 page coloring 页着色等消除重名/使用 PID 进程号来记录 cache 对应关系
   - 加大相联度，强行保证无需地址翻译
   - 对于 L2 以下的 cache 不重要,因为访问 L2 时候必然已经经过了地址翻译

复杂优化有

1. 简单的 L1 缓存， 减少 hit time 和功耗
   - 为了更高的时钟频率和功耗限制
   - 高相联性有助于不加大尺寸提高性能，但会提高功耗
     1. 处理器本身 cache 访问慢
     2. 为了不地址翻译，cache 大小受限于页大小
     3. 多线程程序容易引发 conflict miss
   - 加大 block 大小减少行数以减少索引能耗，但会提高 miss rate
   - 组织 banks， 分块激活
2. 预测组相联的具体 way，加速访问速度，降低 conflict miss
   - I-cache 更容易被预测
   - way-selection：使用预测结果决定实际 cache 访问，适用于低功耗
3. 流水线化缓存访问，多 banks 独立
   - 流水线可提高 L1 时钟频率，会增加延迟，一般针对 I-cache
   - 多 banks 独立针对，对于下级缓存，可以同时处理多个上级缓存缺失
4. nonblocking cache， 提高带宽
   - > **hit under miss** 允许乱序执行规避 stall
   - 乱序执行刻意部分掩盖高层次的 cache miss，但对于高延迟的低层 miss 无效
   - > `Miss Status Handling Registers(MSHRs)`记录缓存 miss 信息，一对一处理
5. 关键词优先，更快重启
   - cache line 比起一次 cache miss 要求的 word 更大，因此只要需要的数据可用，立即返回
6. 融合写缓存
   - 写相近地址的多字比多次写一个字快速
   - **内存映射的 IO 不能写融合**
7. 编译器优化
   - 循环展开
   - blocking 访问
8. 硬件预取
   - 注意预取可能会遇到虚拟内存缺页、权限错误等问题
   - 可能取来无用数据而影响功耗，在高负载下影响性能
9. 编译器控制预取
   - 不能干扰程序执行（比如 register perfetch）
10. HBM：high bandwidth memory
    - 大的 L4 缓存：
      1. 大 block：内部碎片，使用 subblocking 只激活一部分缓解
      2. tag 存储开销大：tag 和数据放在 HBM 同一行中，使用 memory 的行缓存加速访问

### 虚拟存储

1. 保护，保护机制在 page 上
2. 共享,如系统库
3. 管理内存使用和硬盘的 swap

|                        | Page                                                            | Segment                                                                        |
| ---------------------- | --------------------------------------------------------------- | ------------------------------------------------------------------------------ |
| Words per address      | One                                                             | Two (segment and offset)                                                       |
| Programmer visible?    | Invisible to application programmer                             | May be visible to application programmer                                       |
| Replacing a block      | Trivial (all blocks are the same size)                          | Difficult (must find contiguous, variable-size, unused portion of main memory) |
| Memory use             | inefficiency Internal fragmentation (unused portion of page)    | External fragmentation (unused pieces of main memory)                          |
| Efficient disk traffic | Yes (adjust page size to balance access time and transfer time) | Not always (small segments may transfer just a few bytes)                      |

> Translation Look Aside buffer
>
> TLB，快表，作为页表的缓存

| bit                      | usage                                                                                                                                          |
| ------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| Presence                 | page is present in memory                                                                                                                      |
| Read/write               | whether page is read-only or read-write                                                                                                        |
| User/supervisor          | whether a user can access the page or if it is limited to the upper three privilege levels                                                     |
| Dirty                    | if page has been modified                                                                                                                      |
| Accessed                 | if page has been read or written since the bit was last cleared                                                                                |
| Page size                | whether the last level is for 4 KiB pages or 4 MiB pages; if it's the latter, then the Opteron only uses three instead of four levels of pages |
| No execute               | Not found in the 80386 protection scheme, this bit was added to prevent code from executing in some pages                                      |
| Page level cache disable | whether the page can be cached or not                                                                                                          |
| Page level write through | whether the page allows write back or write through for data caches                                                                            |

### virtual machine

1. 用虚拟机隔离 os
   1. 可能有 bug 的操作系统
   2. 云用户
   3. 芯片性能足够开销
2. 兼容和管理软件
3. 管理硬件（可以跨越单台机器）

ISA 设计最好考虑虚拟机，**virtualizable**。保证特权指令在裸 os 和虚拟机的 os 下效果一致。也可以设计更多的特权级（RISCV 的 M、S、U 三态）。TLB 带进程号防止切换 os 频繁刷新。IO 设备也需要 vmm 来划分（如网络）和虚拟化（如硬盘）

> shadow page table
>
> 减少 软件-os-vmm 2 次地址翻译开销，os-vmm 之间直接映射。需要 trap 所有的 os 对页表的改写

> software guard extension
>
> 由进程定义的对内存的加密。上层 os 和 vmm 可以移动数据，不能解密数据

### Fallacy

1. 使用一个程序的访存推断其他程序。程序之间差异很大

### Pitfall

1. 地址空间太小
   - 程序寻址空间大小$2^\text{address}$，太小的地址空间限制大程序
   - 地址空间和`PC`，寄存器等多方面相关，难以后期改变
2. 忽略 os 对存储的性能影响，os 也会造成存储负载
3. 依赖 os 智能调整页大小。os 一般只会针对如数据库和内存映射使用大页，os 不够智能
4. 模拟指令来衡量访存性能
   1. cache 尺寸对于一小部分指令来说太大
   2. 程序不同阶段局部性不一样
   3. 程序对于不同输入局部性不一样
5. 用 cache 但是内存带宽不够
6. 在**virtualizable**有问题的 ISA 上设计虚拟机
   - eg，80x86 的`POPF`指令，在 user mode 下不改变`IE`；在 system mode 下改变。但`POPF`不是特权级指令，vmm 无法 trap 来保证虚拟化

## ch 3/C Instruction-Level Parallelism and Its Exploitation

## ch A Instruction Set Principles

### ISA 特性

对于 ISA 设计，其有如下一些考虑：

1. 指令集类型
   1. 栈
   2. 累加器
   3. 寄存器-内存
   4. 寄存器-寄存器/load-store
2. 地址访问：对齐、不对齐
3. 寻址模式
   1. 立即数 `3`
   2. 寄存器 `Regs[R4]`
   3. 寄存器访存 `Mem[Regs[R4]]`
   4. 寄存器+偏移访存 `Mem[Regs[R4]+10]`
   5. 寄存器+寄存器访存 `Mem[Regs[R3]+Regs[R4]]`
   6. 立即数访存 `Mem[1001]`
   7. PC 相关 `pc`
   8. 寄存器间接访存 `Mem[Mem[Regs[R4]]]`
   9. 自增自减 `Mem[Regs[R2]+=d]`
   10. 寄存器+寄存器倍增访存 `Mem[Regs[R2]+Regs[R3]*d]`
4. 操作数类型：
   1. 整型 `u8,i8,u16,i16,u32,i32,u64,i64`
   2. 浮点数`f32,f64`
   3. 拓展浮点数 80 位
5. 指令类型
   1. 运算和逻辑
   2. 访存
   3. 控制
   4. 系统特权有关
   5. 浮点数指令
   6. decimal 指令
   7. 字符串指令
   8. 图像指令
   9. SIMD
6. 控制流指令
   1. 无条件跳转
   2. 条件转移
   3. 函数调用
   4. 函数 return
7. ISA 编码：
   1. 寄存器数目：对应编译器分配，解依赖，编码长度
   2. 定长，变长
   3. 寄存器编码位置固定/不固定

### 编译器优化

| 编译器层次               | 依赖                                         | 功能                             |
| ------------------------ | -------------------------------------------- | -------------------------------- |
| front end per language   | 语言相关，和机器无关                         | 语言翻译成通用 intermediate 形式 |
| high-level optimizations | 语言相关，基本和机器无关                     | eg，循环展开，函数内连           |
| global optimizer         | 基本语言无关，和机器有关（寄存器数目和类型） | 优化和寄存器分配                 |
| code generator           | 语言无关，机器相关                           | 具体的机器特定优化和指令选择     |

1. 寄存器数目$\ge 16$个以方便启发性的 group coloring 的寄存器分配算法（本质是个$\mathcal{NP}$问题，只有近似线性的启发式算法）
2. 保证常见场景优化+罕见场景正确
3. 操作，数据类型和寻址 3 者可以正交组合
4. 提供 primitive 原语，而不是方案，防止过于适配高层语言
5. 简化 trade-off 的选择
6. 保证编译期常量能直接绑定到指令

SIMD 指令基本上违背所有原则（vec 寄存器数目少，寻址模式过于简单，vec 类型不常见 etc.）。因此 SIMD 一般只有用在人工编写的底层库

### ISA 统计和对应的 RISC-V 设计

### Fallacy

1. 存在一个典型程序：不同程序对 ISA 的使用差异巨大
2. 有缺陷的 ISA 不能成功（80x86）
3. 存在完美的体系结构
   - trade-off 永存
   - 不同技术和时代强调目标不同

### Pitfall

1. 设计一个高层次指令来支持高层语言的结构
   - semantic gap：过于复杂，功能过剩，或者是对于其他语言其约定有差异
2. 设计 ISA 时候不考虑编译器优化
   - 编译器优化等级对于体积优化和性能优化结果差异很大
