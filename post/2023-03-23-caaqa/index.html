<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>笔记：Computer Architecture A Quantatative Approach（更新到第4章） | zhh's blog</title><meta name=keywords content="教程,读书笔记"><meta name=description content="Computer architecture: a quantitative approach ch 1 Fundamentals ch 2/B Memory Hierarchy Design 基础知识 cache 性能优化 虚拟存储 virtual machine Fallacy Pitfall ch 3/C Instruction-Level Parallelism and Its Exploitation 编译器优化 ILP 循环展开 5 级流水 前递 乱序 Scoreboard Tomasulo 硬件预测 多发射 VLIW 分支预测 静"><meta name=author content="livypad"><link rel=canonical href=https://livypad.github.io/post/2023-03-23-caaqa/><link crossorigin=anonymous href=/assets/css/stylesheet.min.7ca4c3dd9394a71fbe69a066b9fbc3dcfe7fb50ce978b051497ffe24c8e1c49a.css integrity="sha256-fKTD3ZOUpx++aaBmufvD3P5/tQzpeLBRSX/+JMjhxJo=" rel="preload stylesheet" as=style><link rel=icon href=https://livypad.github.io/assets/icon/favicon.ico><link rel=apple-touch-icon href=https://livypad.github.io/assets/icon/apple-touch-icon.png><link rel=manifest href=https://livypad.github.io/assets/icon/site.webmanifest><meta name=twitter:title content="笔记：Computer Architecture A Quantatative Approach（更新到第4章） | zhh's blog"><meta name=twitter:description content="Computer architecture: a quantitative approach ch 1 Fundamentals ch 2/B Memory Hierarchy Design 基础知识 cache 性能优化 虚拟存储 virtual machine Fallacy Pitfall ch 3/C Instruction-Level Parallelism and Its Exploitation 编译器优化 ILP 循环展开 5 级流水 前递 乱序 Scoreboard Tomasulo 硬件预测 多发射 VLIW 分支预测 静"><meta name=twitter:site content="@novoreorx"><meta name=twitter:creator content="@novoreorx"><meta property="og:title" content><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary-bg:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript></head><body id=top><script data-no-instant>function switchTheme(e){switch(e){case"light":document.body.classList.remove("dark");break;case"dark":document.body.classList.add("dark");break;default:window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")}}function isDarkTheme(){return document.body.className.includes("dark")}function getPrefTheme(){return localStorage.getItem("pref-theme")}function setPrefTheme(e){switchTheme(e),localStorage.setItem("pref-theme",e)}const toggleThemeCallbacks={};toggleThemeCallbacks.main=e=>{setPrefTheme(e?"light":"dark")},window.addEventListener("toggle-theme",function(){const e=isDarkTheme();for(const t in toggleThemeCallbacks)toggleThemeCallbacks[t](e)});function toggleThemeListener(){window.dispatchEvent(new CustomEvent("toggle-theme"))}</script><script>(function(){const t="auto",e=getPrefTheme(),n=e||t;switchTheme(n)})()</script><header class=header><nav class=nav><div class=logo><a href=https://livypad.github.io accesskey=h title="zhh's blog (Alt + H)">zhh's blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://livypad.github.io/about/ title=About>About</a></li><li><a href=https://livypad.github.io/tags/ title=Tags>Tags</a></li><li><a href=https://livypad.github.io/archives/ title=Archive>Archive</a></li><li><a href=https://livypad.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/ title=Note>Note</a></li></ul></nav></header><main class="main post"><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://livypad.github.io>Home</a>&nbsp;»&nbsp;<a href=https://livypad.github.io/post/>Posts</a></div><h1 class=post-title>笔记：Computer Architecture A Quantatative Approach（更新到第4章）</h1><div class=post-meta><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg><span>2023-05-05</span></span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select:text"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z" style="user-select:text"/><line x1="7" y1="7" x2="7" y2="7" style="user-select:text"/></svg>
<a href=https://livypad.github.io/tags/%E6%95%99%E7%A8%8B/>教程 </a><a href=https://livypad.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/>读书笔记</a>
</span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg><span>14210 words</span></span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>29 min</span></span></div></header><div class="toc side left"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#computer-architecture-a-quantitative-approach aria-label="Computer architecture: a quantitative approach">Computer architecture: a quantitative approach</a><ul><li><a href=#ch-1-fundamentals aria-label="ch 1 Fundamentals">ch 1 Fundamentals</a></li><li><a href=#ch-2b-memory-hierarchy-design aria-label="ch 2/B Memory Hierarchy Design">ch 2/B Memory Hierarchy Design</a><ul><li><a href=#%e5%9f%ba%e7%a1%80%e7%9f%a5%e8%af%86 aria-label=基础知识>基础知识</a></li><li><a href=#cache-%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96 aria-label="cache 性能优化">cache 性能优化</a></li><li><a href=#%e8%99%9a%e6%8b%9f%e5%ad%98%e5%82%a8 aria-label=虚拟存储>虚拟存储</a></li><li><a href=#virtual-machine aria-label="virtual machine">virtual machine</a></li><li><a href=#fallacy aria-label=Fallacy>Fallacy</a></li><li><a href=#pitfall aria-label=Pitfall>Pitfall</a></li></ul></li><li><a href=#ch-3c-instruction-level-parallelism-and-its-exploitation aria-label="ch 3/C Instruction-Level Parallelism and Its Exploitation">ch 3/C Instruction-Level Parallelism and Its Exploitation</a><ul><li><a href=#%e7%bc%96%e8%af%91%e5%99%a8%e4%bc%98%e5%8c%96-ilp aria-label="编译器优化 ILP">编译器优化 ILP</a><ul><li><a href=#%e5%be%aa%e7%8e%af%e5%b1%95%e5%bc%80 aria-label=循环展开>循环展开</a></li></ul></li><li><a href=#5-%e7%ba%a7%e6%b5%81%e6%b0%b4 aria-label="5 级流水">5 级流水</a><ul><li><a href=#%e5%89%8d%e9%80%92 aria-label=前递>前递</a></li></ul></li><li><a href=#%e4%b9%b1%e5%ba%8f aria-label=乱序>乱序</a><ul><li><a href=#scoreboard aria-label=Scoreboard>Scoreboard</a></li><li><a href=#tomasulo aria-label=Tomasulo>Tomasulo</a></li><li><a href=#%e7%a1%ac%e4%bb%b6%e9%a2%84%e6%b5%8b aria-label=硬件预测>硬件预测</a></li></ul></li><li><a href=#%e5%a4%9a%e5%8f%91%e5%b0%84 aria-label=多发射>多发射</a><ul><li><a href=#vliw aria-label=VLIW>VLIW</a></li></ul></li><li><a href=#%e5%88%86%e6%94%af%e9%a2%84%e6%b5%8b aria-label=分支预测>分支预测</a><ul><li><a href=#%e9%9d%99%e6%80%81%e9%a2%84%e6%b5%8b aria-label=静态预测>静态预测</a></li><li><a href=#2-bitn-bit aria-label=2-bit/n-bit>2-bit/n-bit</a></li><li><a href=#mn%e9%a2%84%e6%b5%8b%e5%99%a8 aria-label=(m,n)预测器>(m,n)预测器</a></li><li><a href=#g-share-%e9%a2%84%e6%b5%8b%e5%99%a8 aria-label="g-share 预测器">g-share 预测器</a></li><li><a href=#tournament%e9%94%a6%e6%a0%87%e8%b5%9b%e9%a2%84%e6%b5%8b%e5%99%a8 aria-label=Tournament（锦标赛）预测器>Tournament（锦标赛）预测器</a></li><li><a href=#tagged-hybridtage-%e9%a2%84%e6%b5%8b%e5%99%a8 aria-label="Tagged Hybrid/TAGE 预测器">Tagged Hybrid/TAGE 预测器</a></li></ul></li><li><a href=#%e5%a4%9a%e5%91%a8%e6%9c%9f%e6%8c%87%e4%bb%a4 aria-label=多周期指令>多周期指令</a></li><li><a href=#%e4%b8%ad%e6%96%ad%e5%bc%82%e5%b8%b8 aria-label=中断/异常>中断/异常</a></li><li><a href=#pitfall-1 aria-label=Pitfall>Pitfall</a></li><li><a href=#fallacy-1 aria-label=Fallacy>Fallacy</a></li></ul></li><li><a href=#ch-4-data-level-parallelism-in-vector-simd-and-gpu-architectures aria-label="ch 4 Data-Level Parallelism in Vector, SIMD, and GPU Architectures">ch 4 Data-Level Parallelism in Vector, SIMD, and GPU Architectures</a><ul><li><a href=#roofline-model aria-label=Roofline-Model>Roofline-Model</a></li><li><a href=#%e5%90%91%e9%87%8f%e6%9e%b6%e6%9e%84 aria-label=向量架构>向量架构</a></li><li><a href=#%e9%9d%a2%e5%90%91%e5%a4%9a%e5%aa%92%e4%bd%93%e7%9a%84-simd-%e6%89%a9%e5%b1%95 aria-label="面向多媒体的 SIMD 扩展">面向多媒体的 SIMD 扩展</a></li><li><a href=#gpu aria-label=GPU>GPU</a><ul><li><a href=#cuda aria-label=CUDA>CUDA</a></li><li><a href=#%e5%b1%82%e6%ac%a1%e7%bb%93%e6%9e%84 aria-label=层次结构>层次结构</a></li><li><a href=#%e5%af%b9%e7%85%a7 aria-label=对照>对照</a></li></ul></li><li><a href=#loop-level-parallelism-%e6%94%b9%e8%bf%9b aria-label="Loop-level parallelism 改进">Loop-level parallelism 改进</a><ul><li><a href=#%e4%be%9d%e8%b5%96%e6%a3%80%e6%b5%8b aria-label=依赖检测>依赖检测</a></li><li><a href=#%e5%8f%a6%e4%b8%80%e7%a7%8d%e4%be%9d%e8%b5%96%e6%b6%88%e9%99%a4 aria-label=另一种依赖消除>另一种依赖消除</a></li></ul></li><li><a href=#fallacy-2 aria-label=Fallacy>Fallacy</a></li><li><a href=#pitfall-2 aria-label=Pitfall>Pitfall</a></li></ul></li><li><a href=#ch-a-instruction-set-principles aria-label="ch A Instruction Set Principles">ch A Instruction Set Principles</a><ul><li><a href=#isa-%e7%89%b9%e6%80%a7 aria-label="ISA 特性">ISA 特性</a></li><li><a href=#%e7%bc%96%e8%af%91%e5%99%a8%e4%bc%98%e5%8c%96 aria-label=编译器优化>编译器优化</a></li><li><a href=#isa-%e7%bb%9f%e8%ae%a1%e5%92%8c%e5%af%b9%e5%ba%94%e7%9a%84-risc-v-%e8%ae%be%e8%ae%a1 aria-label="ISA 统计和对应的 RISC-V 设计">ISA 统计和对应的 RISC-V 设计</a></li><li><a href=#fallacy-3 aria-label=Fallacy>Fallacy</a></li><li><a href=#pitfall-3 aria-label=Pitfall>Pitfall</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><ul><li><a href=#computer-architecture-a-quantitative-approach>Computer architecture: a quantitative approach</a><ul><li><a href=#ch-1-fundamentals>ch 1 Fundamentals</a></li><li><a href=#ch-2b-memory-hierarchy-design>ch 2/B Memory Hierarchy Design</a><ul><li><a href=#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86>基础知识</a></li><li><a href=#cache-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96>cache 性能优化</a></li><li><a href=#%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8>虚拟存储</a></li><li><a href=#virtual-machine>virtual machine</a></li><li><a href=#fallacy>Fallacy</a></li><li><a href=#pitfall>Pitfall</a></li></ul></li><li><a href=#ch-3c-instruction-level-parallelism-and-its-exploitation>ch 3/C Instruction-Level Parallelism and Its Exploitation</a><ul><li><a href=#%E7%BC%96%E8%AF%91%E5%99%A8%E4%BC%98%E5%8C%96-ilp>编译器优化 ILP</a><ul><li><a href=#%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80>循环展开</a></li></ul></li><li><a href=#5-%E7%BA%A7%E6%B5%81%E6%B0%B4>5 级流水</a><ul><li><a href=#%E5%89%8D%E9%80%92>前递</a></li></ul></li><li><a href=#%E4%B9%B1%E5%BA%8F>乱序</a><ul><li><a href=#scoreboard>Scoreboard</a></li><li><a href=#tomasulo>Tomasulo</a></li><li><a href=#%E7%A1%AC%E4%BB%B6%E9%A2%84%E6%B5%8B>硬件预测</a></li></ul></li><li><a href=#%E5%A4%9A%E5%8F%91%E5%B0%84>多发射</a><ul><li><a href=#vliw>VLIW</a></li></ul></li><li><a href=#%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B>分支预测</a><ul><li><a href=#%E9%9D%99%E6%80%81%E9%A2%84%E6%B5%8B>静态预测</a></li><li><a href=#2-bitn-bit>2-bit/n-bit</a></li><li><a href=#mn%E9%A2%84%E6%B5%8B%E5%99%A8>(m,n)预测器</a></li><li><a href=#g-share-%E9%A2%84%E6%B5%8B%E5%99%A8>g-share 预测器</a></li><li><a href=#tournament%E9%94%A6%E6%A0%87%E8%B5%9B%E9%A2%84%E6%B5%8B%E5%99%A8>Tournament（锦标赛）预测器</a></li><li><a href=#tagged-hybridtage-%E9%A2%84%E6%B5%8B%E5%99%A8>Tagged Hybrid/TAGE 预测器</a></li></ul></li><li><a href=#%E5%A4%9A%E5%91%A8%E6%9C%9F%E6%8C%87%E4%BB%A4>多周期指令</a></li><li><a href=#%E4%B8%AD%E6%96%AD%E5%BC%82%E5%B8%B8>中断/异常</a></li><li><a href=#pitfall-1>Pitfall</a></li><li><a href=#fallacy-1>Fallacy</a></li></ul></li><li><a href=#ch-4-data-level-parallelism-in-vector-simd-and-gpu-architectures>ch 4 Data-Level Parallelism in Vector, SIMD, and GPU Architectures</a><ul><li><a href=#roofline-model>Roofline-Model</a></li><li><a href=#%E5%90%91%E9%87%8F%E6%9E%B6%E6%9E%84>向量架构</a></li><li><a href=#%E9%9D%A2%E5%90%91%E5%A4%9A%E5%AA%92%E4%BD%93%E7%9A%84-simd-%E6%89%A9%E5%B1%95>面向多媒体的 SIMD 扩展</a></li><li><a href=#gpu>GPU</a><ul><li><a href=#cuda>CUDA</a></li><li><a href=#%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84>层次结构</a></li><li><a href=#%E5%AF%B9%E7%85%A7>对照</a></li></ul></li><li><a href=#loop-level-parallelism-%E6%94%B9%E8%BF%9B>Loop-level parallelism 改进</a><ul><li><a href=#%E4%BE%9D%E8%B5%96%E6%A3%80%E6%B5%8B>依赖检测</a></li><li><a href=#%E5%8F%A6%E4%B8%80%E7%A7%8D%E4%BE%9D%E8%B5%96%E6%B6%88%E9%99%A4>另一种依赖消除</a></li></ul></li><li><a href=#fallacy-2>Fallacy</a></li><li><a href=#pitfall-2>Pitfall</a></li></ul></li><li><a href=#ch-a-instruction-set-principles>ch A Instruction Set Principles</a><ul><li><a href=#isa-%E7%89%B9%E6%80%A7>ISA 特性</a></li><li><a href=#%E7%BC%96%E8%AF%91%E5%99%A8%E4%BC%98%E5%8C%96>编译器优化</a></li><li><a href=#isa-%E7%BB%9F%E8%AE%A1%E5%92%8C%E5%AF%B9%E5%BA%94%E7%9A%84-risc-v-%E8%AE%BE%E8%AE%A1>ISA 统计和对应的 RISC-V 设计</a></li><li><a href=#fallacy-3>Fallacy</a></li><li><a href=#pitfall-3>Pitfall</a></li></ul></li></ul></li></ul><h1 id=computer-architecture-a-quantitative-approach>Computer architecture: a quantitative approach<a hidden class=anchor aria-hidden=true href=#computer-architecture-a-quantitative-approach>¶</a></h1><h2 id=ch-1-fundamentals>ch 1 Fundamentals<a hidden class=anchor aria-hidden=true href=#ch-1-fundamentals>¶</a></h2><ul><li>Internet of Things/Embedded Computers：缺乏量化基准</li><li>Personal Mobile Device：soft real time（对实时性的要求），功耗优化</li><li>Desktop Computing：性价比</li><li>Servers：可用性，可拓展性，有效吞吐</li><li>Warehouse：性价比，功耗</li></ul><h2 id=ch-2b-memory-hierarchy-design>ch 2/B Memory Hierarchy Design<a hidden class=anchor aria-hidden=true href=#ch-2b-memory-hierarchy-design>¶</a></h2><h3 id=基础知识>基础知识<a hidden class=anchor aria-hidden=true href=#基础知识>¶</a></h3><p>cache 基本配置有</p><ol><li><p>block 可放置位置</p><ol><li>direct mapped：直接映射，$(Block\ Address)\mod(Number\ of\ blocks)$</li><li>fully associative：全相联，cache 中任意位置</li><li>set associative：组相联，在对应组中的任意位置，$(Block\ Address)\mod(Number\ of\ sets)$</li></ol></li><li><p>替换算法</p><ol><li>random：效果不差，但是缺乏确定性，对程序优化不友好</li><li>FIFO：first-in-first-out，可能导致抖动</li><li>LRU：Least recently used，较优，但算法复杂，一般采用简化版，如 clock 算法</li></ol></li><li><p>写策略</p><ul><li>写命中 cache 时候<ol><li>write through：写穿透，cache 和底层都写，保持一致性容易</li><li>write back：写回，只写 cache，之后 cache 写回底层，性能较好</li></ol></li><li>写不命中时候，常常使用<code>write buffer</code>减少写带来的 stall<ol><li>write allocate：写分配</li><li>No-write allocate：写不分配</li></ol></li></ul></li></ol><h3 id=cache-性能优化>cache 性能优化<a hidden class=anchor aria-hidden=true href=#cache-性能优化>¶</a></h3><p>优化目标为平均访问时间，有</p><p>$$
\mathrm{Average\ memory\ access\ time}=\mathrm{Hit\ time} + \mathrm{Miss\ rate}\times \mathrm{Miss\ penalty}
$$</p><p>当中，可以把 miss 分类有</p><ol><li>compulsory miss：第一次访存必然 miss</li><li>capacity miss：cache 容量有限，一些 block 被丢弃后再被访问</li><li>conflict miss：cache 不是全相联，set 满而部分 block 被丢弃后再被访问</li><li>coherence miss：多核时候，其他核修改导致数据过时而失效</li></ol><p>简单优化有</p><ol><li>增大 block ，减少 miss rate<ul><li>利用 spacial locality：空间局部性，可以减少 compulsory miss</li><li>可能增大 miss penalty</li><li>在 cache 大小固定时候，过大的 block 大小会增加 conflict miss</li></ul></li><li>增大 cache ，减少 miss rate<ul><li>可能增加 hit time</li><li>可能增加成本和功耗</li></ul></li><li>增加关联度<ul><li>比较电路设计麻烦，可能提高 hit time</li><li>8-way 组相联和全相联一般表现类似</li><li><blockquote><p>2:1 cache rule of thumb</p><p>大小 N 的 direct mapped 和$\frac{N}{2}$的 2-way set associative 一般 miss rate 相似（经验公式）</p></blockquote></li><li>可能增加 hit time，高关联性会要求更低的时钟频率</li></ul></li><li>多级 cache<ul><li>multilevel inclusion/ multilevel exclusion</li><li>平衡 fast hit 和 few misses</li></ul></li><li>read miss 优先于 write miss， 减少 miss penalty<ul><li>read miss 一般和取指，取数计算有关，优先可以减少程序的 stall</li><li>写缓存可能导致数据不一致，等写回内存用时过长</li></ul></li><li>在 cache 内索引时避开地址翻译， 降低 hit time<ul><li>VIVT 对于保护,重名不利</li><li>VIPT 需要如 page coloring 页着色等消除重名/使用 PID 进程号来记录 cache 对应关系</li><li>加大相联度，强行保证无需地址翻译</li><li>对于 L2 以下的 cache 不重要,因为访问 L2 时候必然已经经过了地址翻译</li></ul></li></ol><p>复杂优化有</p><ol><li>简单的 L1 缓存， 减少 hit time 和功耗<ul><li>为了更高的时钟频率和功耗限制</li><li>高相联性有助于不加大尺寸提高性能，但会提高功耗<ol><li>处理器本身 cache 访问慢</li><li>为了不地址翻译，cache 大小受限于页大小</li><li>多线程程序容易引发 conflict miss</li></ol></li><li>加大 block 大小减少行数以减少索引能耗，但会提高 miss rate</li><li>组织 banks， 分块激活</li></ul></li><li>预测组相联的具体 way，加速访问速度，降低 conflict miss<ul><li>I-cache 更容易被预测</li><li>way-selection：使用预测结果决定实际 cache 访问，适用于低功耗</li></ul></li><li>流水线化缓存访问，多 banks 独立<ul><li>流水线可提高 L1 时钟频率，会增加延迟，一般针对 I-cache</li><li>多 banks 独立针对，对于下级缓存，可以同时处理多个上级缓存缺失</li></ul></li><li>nonblocking cache， 提高带宽<ul><li><blockquote><p><strong>hit under miss</strong> 允许乱序执行规避 stall</p></blockquote></li><li>乱序执行刻意部分掩盖高层次的 cache miss，但对于高延迟的低层 miss 无效</li><li><blockquote><p><code>Miss Status Handling Registers(MSHRs)</code>记录缓存 miss 信息，一对一处理</p></blockquote></li></ul></li><li>关键词优先，更快重启<ul><li>cache line 比起一次 cache miss 要求的 word 更大，因此只要需要的数据可用，立即返回</li></ul></li><li>融合写缓存<ul><li>写相近地址的多字比多次写一个字快速</li><li><strong>内存映射的 IO 不能写融合</strong></li></ul></li><li>编译器优化<ul><li>循环展开</li><li>blocking 访问</li></ul></li><li>硬件预取<ul><li>注意预取可能会遇到虚拟内存缺页、权限错误等问题</li><li>可能取来无用数据而影响功耗，在高负载下影响性能</li></ul></li><li>编译器控制预取<ul><li>不能干扰程序执行（比如 register perfetch）</li></ul></li><li>HBM：high bandwidth memory<ul><li>大的 L4 缓存：<ol><li>大 block：内部碎片，使用 subblocking 只激活一部分缓解</li><li>tag 存储开销大：tag 和数据放在 HBM 同一行中，使用 memory 的行缓存加速访问</li></ol></li></ul></li></ol><h3 id=虚拟存储>虚拟存储<a hidden class=anchor aria-hidden=true href=#虚拟存储>¶</a></h3><ol><li>保护，保护机制在 page 上</li><li>共享,如系统库</li><li>管理内存使用和硬盘的 swap</li></ol><table><thead><tr><th></th><th>Page</th><th>Segment</th></tr></thead><tbody><tr><td>Words per address</td><td>One</td><td>Two (segment and offset)</td></tr><tr><td>Programmer visible?</td><td>Invisible to application programmer</td><td>May be visible to application programmer</td></tr><tr><td>Replacing a block</td><td>Trivial (all blocks are the same size)</td><td>Difficult (must find contiguous, variable-size, unused portion of main memory)</td></tr><tr><td>Memory use</td><td>inefficiency Internal fragmentation (unused portion of page)</td><td>External fragmentation (unused pieces of main memory)</td></tr><tr><td>Efficient disk traffic</td><td>Yes (adjust page size to balance access time and transfer time)</td><td>Not always (small segments may transfer just a few bytes)</td></tr></tbody></table><blockquote><p>Translation Look Aside buffer</p><p>TLB，快表，作为页表的缓存</p></blockquote><table><thead><tr><th>bit</th><th>usage</th></tr></thead><tbody><tr><td>Presence</td><td>page is present in memory</td></tr><tr><td>Read/write</td><td>whether page is read-only or read-write</td></tr><tr><td>User/supervisor</td><td>whether a user can access the page or if it is limited to the upper three privilege levels</td></tr><tr><td>Dirty</td><td>if page has been modified</td></tr><tr><td>Accessed</td><td>if page has been read or written since the bit was last cleared</td></tr><tr><td>Page size</td><td>whether the last level is for 4 KiB pages or 4 MiB pages; if it&rsquo;s the latter, then the Opteron only uses three instead of four levels of pages</td></tr><tr><td>No execute</td><td>Not found in the 80386 protection scheme, this bit was added to prevent code from executing in some pages</td></tr><tr><td>Page level cache disable</td><td>whether the page can be cached or not</td></tr><tr><td>Page level write through</td><td>whether the page allows write back or write through for data caches</td></tr></tbody></table><h3 id=virtual-machine>virtual machine<a hidden class=anchor aria-hidden=true href=#virtual-machine>¶</a></h3><ol><li>用虚拟机隔离 os<ol><li>可能有 bug 的操作系统</li><li>云用户</li><li>芯片性能足够开销</li></ol></li><li>兼容和管理软件</li><li>管理硬件（可以跨越单台机器）</li></ol><p>ISA 设计最好考虑虚拟机，<strong>virtualizable</strong>。保证特权指令在裸 os 和虚拟机的 os 下效果一致。也可以设计更多的特权级（RISCV 的 M、S、U 三态）。TLB 带进程号防止切换 os 频繁刷新。IO 设备也需要 vmm 来划分（如网络）和虚拟化（如硬盘）</p><blockquote><p>shadow page table</p><p>减少 软件-os-vmm 2 次地址翻译开销，os-vmm 之间直接映射。需要 trap 所有的 os 对页表的改写</p></blockquote><blockquote><p>software guard extension</p><p>由进程定义的对内存的加密。上层 os 和 vmm 可以移动数据，不能解密数据</p></blockquote><h3 id=fallacy>Fallacy<a hidden class=anchor aria-hidden=true href=#fallacy>¶</a></h3><ol><li>使用一个程序的访存推断其他程序。程序之间差异很大</li></ol><h3 id=pitfall>Pitfall<a hidden class=anchor aria-hidden=true href=#pitfall>¶</a></h3><ol><li>地址空间太小<ul><li>程序寻址空间大小$2^\text{address}$，太小的地址空间限制大程序</li><li>地址空间和<code>PC</code>，寄存器等多方面相关，难以后期改变</li></ul></li><li>忽略 os 对存储的性能影响，os 也会造成存储负载</li><li>依赖 os 智能调整页大小。os 一般只会针对如数据库和内存映射使用大页，os 不够智能</li><li>模拟指令来衡量访存性能<ol><li>cache 尺寸对于一小部分指令来说太大</li><li>程序不同阶段局部性不一样</li><li>程序对于不同输入局部性不一样</li></ol></li><li>用 cache 但是内存带宽不够</li><li>在<strong>virtualizable</strong>有问题的 ISA 上设计虚拟机<ul><li>eg，80x86 的<code>POPF</code>指令，在 user mode 下不改变<code>IE</code>；在 system mode 下改变。但<code>POPF</code>不是特权级指令，vmm 无法 trap 来保证虚拟化</li></ul></li></ol><h2 id=ch-3c-instruction-level-parallelism-and-its-exploitation>ch 3/C Instruction-Level Parallelism and Its Exploitation<a hidden class=anchor aria-hidden=true href=#ch-3c-instruction-level-parallelism-and-its-exploitation>¶</a></h2><p>主要关注的是 basic block（只在代码块出入口有跳转，平均几行规模）和多个 basic block 级别的并行性。程序天然的存在依赖关系。优化需要保证依赖关系以保证正确的输出</p><ol><li>data dependence（RAW）<ul><li>前一条指令的结果是后一条指令的输入</li><li>有传递性</li><li>存在于内存的 data depedence 比起寄存器之间的更难检测</li></ul></li><li>name dependence，在指令使用相同的寄存器（一般靠寄存器重命名消除）/内存地址（称为 name）时候出现<ol><li>antidepedence：前一条指令写后一条指令的读（WAR）</li><li>output dependence：两条指令同时写一个寄存器/内存地址（WAW）</li></ol></li><li>control depedence：指令的执行条件不能被更改，不一定会被完美保持，而是保持能维护正确性的重要的 dependence<ol><li>exception behavior：保证修改指令序列不会导致异常的行为变动（eg，发生本来没有的异常）</li><li>data flow：保证指令的数据来自正确的前面的指令，即使可能有多条指令和其有潜在的 data dependence（eg，正确选择来自某个分支的结果）</li></ol></li></ol><p>如果有依赖关系的指令距离很近，导致不能并行/重叠执行等，就会造成 hazard 使得处理器必须特别处理</p><ol><li>structural hazard：功能部件不能满足同时访问</li><li>data hazard：数据依赖（按照正确执行应该保持的顺序来命名）<ol><li>Read After Write：RAW，真相关</li><li>Write After Read：WAR，只有乱序时候出现</li><li>Write After Write：WAW，只有乱序时候出现</li></ol></li><li>control hazard：跳转和其他改变<code>pc</code>的指令</li></ol><h3 id=编译器优化-ilp>编译器优化 ILP<a hidden class=anchor aria-hidden=true href=#编译器优化-ilp>¶</a></h3><ol><li>对于指针和引用，编译期的依赖关系难以检测</li><li>硬件预测一般能保证精确异常</li><li>有些程序的<a href=#%E9%9D%99%E6%80%81%E9%A2%84%E6%B5%8B>静态预测分支</a>效果很差（整数控制程序，如数据库）</li><li>硬件预测不需要使用额外代码而增加代码体积</li><li>编译器可以调度更大范围内的依赖关系</li><li>硬件预测不需要对不同处理器架构针对性优化</li><li>硬件预测会导致复杂的控制逻辑，更多晶体管面积和能耗</li></ol><h4 id=循环展开>循环展开<a hidden class=anchor aria-hidden=true href=#循环展开>¶</a></h4><p>loop unrolling。减少循环判断次数，一个循环体里执行原先多个循环的内容。如果是未知的需要迭代$n$次，展开尺寸$k$，那么需要$\frac{n}{k}$次循环展开，$n\mod k$次原本的循环</p><ol><li>减少判断和跳转的指令数目，以及其潜在的延迟</li><li>在更大的循环体里调度指令消除 data hazard 更容易<ol><li>尽量用不同寄存器防止 name dependence</li><li>更改<code>load,store</code>顺序来遮盖访存延迟</li></ol></li><li>会增加代码体积；过度展开会导致 cache 性能差；通用寄存器数目有限，展开次数有上限</li></ol><h3 id=5-级流水>5 级流水<a hidden class=anchor aria-hidden=true href=#5-级流水>¶</a></h3><table><thead><tr><th>全称</th><th>简称</th><th>效果</th><th>伪代码</th></tr></thead><tbody><tr><td>instruction fetch cycle</td><td>IF</td><td>按照<code>pc</code>取指令，并<code>pc+=4</code></td><td><code>IR&lt;-Mem[PC],NPC&lt;-PC+4</code></td></tr><tr><td>instruction decode/register fetch cycle</td><td>ID</td><td>指令译码，符号拓展偏移值，预测<code>pc</code>跳转地址，读寄存器（RISCV 的寄存器和立即数位置固定，可以在不在意功耗场合默认读取）</td><td><code>A&lt;-Regs[rs1],B&lt;-Regs[rs2], Imm&lt;-sign-extended immediate field of IR;</code></td></tr><tr><td>execution/effective address cycle</td><td>EX</td><td>1. 内存访问：ALU 计算基址+偏移 2. 寄存器-寄存器 ALU 3. 寄存器-立即数 ALU 4. 条件跳转：判断是否跳转。 对于 load-store 的 ISA（如 RISCV）执行和计算地址可以合并为一个周期</td><td><code>ALUOutput&lt;- A + Imm;ALUOutput&lt;-A func B;ALUOutput&lt;-A op Imm;ALUOutput&lt;-NPC+(Imm&lt;&lt;2),Cond&lt;-(A?=B)</code></td></tr><tr><td>memory access</td><td>MEM</td><td>访存</td><td><code>LMD&lt;-Mem[ALUOutput] or Mem[ALUOutput]&lt;-B;if(Cond)PC&lt;-ALUOutput else PC&lt;-NPC</code></td></tr><tr><td>write-back cycle</td><td>WB</td><td>访存/ALU 运算结果写回寄存器文件</td><td><code>Regs[rd]&lt;-ALUOutput;Regs[rd]&lt;-LMD</code></td></tr></tbody></table><p>有一些注意事项</p><ol><li>分开 Icache 和 Dcache 保证一个 cycle 内取指和访存指令的访存不冲突</li><li>对于流水的 CPU，访存频率更高，要求更高的内存带宽</li><li>寄存器文件在 ID 时候需要 2 个读端口，WB 时候 1 个写端口</li><li>中间结果需要 pipeline registers 缓存下来，<code>IF/ID,ID/EX,EX/MEM,MEM/WB</code></li><li>流水线的单一指令延迟会增加<ol><li>最慢的阶段限制整体时钟频率</li><li>pipeline register 读写和传播时间</li></ol></li></ol><p>流水线会遭遇 hazard 使得性能不如理论值。（暂停，清空等）</p><h4 id=前递>前递<a hidden class=anchor aria-hidden=true href=#前递>¶</a></h4><p>forwarding，bypassing，short-circuiting。</p><p>把已经计算出来的被依赖的结果不等 WB 写回寄存器，直接传给需要的功能部件。</p><table><thead><tr><th>目标 pipeline register</th><th>目标指令类型</th><th>源 Pipeline register</th><th>源指令类型</th><th>前递位置</th><th>前递的条件</th></tr></thead><tbody><tr><td>EX/MEM</td><td>寄存器-寄存器，立即数</td><td>ID/EX</td><td>寄存器-寄存器，立即数, load, store, branch</td><td>ALU 操作数 1</td><td><code>EX/MEM.IR[rd] == ID/EX.IR[rs1]</code></td></tr><tr><td>EX/MEM</td><td>寄存器-寄存器，立即数</td><td>ID/EX</td><td>寄存器-寄存器</td><td>ALU 操作数 2</td><td><code>EX/MEM.IR[rd] == ID/EX.IR[rs2]</code></td></tr><tr><td>MEM/WB</td><td>寄存器-寄存器，立即数, Load</td><td>ID/EX</td><td>寄存器-寄存器，立即数, load, store, branch</td><td>ALU 操作数 1</td><td><code>MEM/WB.IR[rd] == ID/EX.IR[rs1]</code></td></tr><tr><td>MEM/WB</td><td>寄存器-寄存器，立即数, Load</td><td>ID/EX</td><td>寄存器-寄存器</td><td>ALU 操作数 2</td><td><code>MEM/WB.IR[rd] == ID/EX.IR[rs2]</code></td></tr></tbody></table><p>前递不是万能的。如果是上下两条指令之间依赖，需要比如在 ID 阶段暂停流水线。比如对于依赖 load 指令结果的 RAW 依赖，需要实现<strong>load interlock</strong></p><table><thead><tr><th>需要 stall 的 IF/ID 指令类型</th><th>判断条件</th></tr></thead><tbody><tr><td>寄存器-寄存器, load, store, 立即数, branch</td><td><code>ID/EX.IR[rd]== IF/ID.IR[rs1]</code></td></tr><tr><td>寄存器-寄存器, branch</td><td><code>ID/EX.IR[rd]==IF/ID.IR[rs2]</code></td></tr></tbody></table><h3 id=乱序>乱序<a hidden class=anchor aria-hidden=true href=#乱序>¶</a></h3><ol><li>减轻对特定架构编译的依赖，二进制分发有效率</li><li>应对编译期未知的依赖</li><li>应对不可预计的停顿，如 cache miss</li></ol><h4 id=scoreboard>Scoreboard<a hidden class=anchor aria-hidden=true href=#scoreboard>¶</a></h4><p>CDC6600 开始采用的乱序执行机制。scoreboard 会记录和管理依赖关系。指令会首先顺序被 scoreboard issue（发射）。这套方法没有<a href=#%E5%89%8D%E9%80%92>前递</a>，因为是乱序执行，指令不需要等到自己的 WB 才能写进寄存器。但写寄存器和读之间还是需要 stall 一个周期。而且需要处理读写寄存器的总线的 structural hazards。</p><ol><li>issue：直到没有 structural hazard 和 WAW，功能部件空闲时候指令发射。暂停时候，指令队列可以接着取值</li><li>read operands：没有指令会写 operands 时候读寄存器，这样动态解决 RAW</li><li>excution：执行指令</li><li>write result：直到没有 WAR 时候写完成的结果</li></ol><h4 id=tomasulo>Tomasulo<a hidden class=anchor aria-hidden=true href=#tomasulo>¶</a></h4><p>动态决定指令开始执行的时机以及寄存器重命名来消除 WAW、WAR。</p><blockquote><p>register renaming</p><p>寄存器重命名。将目的寄存器重命名，避免乱序完成影响实际的操作数。既可以编译器实现（在逻辑寄存器充足时），也可以硬件实现（在物理寄存器多于逻辑寄存器时）</p></blockquote><blockquote><p>reservation stations</p><p>保留站。缓存指令的类型，操作数，结果等信息，有：</p><ul><li>Op：操作</li><li>Qj,Qk：操作数来源的保留站号，为 0 表示操作数就绪/不需要</li><li>Vj,Vk：操作数的值。对于<code>load</code>指令，Vk 表示偏移</li><li>A：访存计算出来的地址</li><li>Busy：表示保留站和对应功能部件占用中</li></ul><p>对应的，寄存器文件有：</p><ul><li>Qi：表示结果来源的保留站号，如果为空/0，目前没有指令目标寄存器是自己</li></ul></blockquote><blockquote><p>common data bus</p><p>CDB。在 360/91 上，允许多个部件同时读可用的操作数，以实现<a href=#%E5%89%8D%E9%80%92>前递</a></p></blockquote><ol><li>issue：从 FIFO 的指令队列里面，取第一条指令。这一步会完成寄存器重命名解决 WAW、WAR，有时该阶段被称为 <em>dispatch</em><ol><li>对应保留站空闲，发射指令</li><li>对应操作数就绪，读寄存器文件，否则追踪对应的功能部件，等结果</li><li>对应保留站忙碌，出现 structural hazard，stall 指令</li></ol></li><li>execute：等操作数以解决 RAW<ol><li>如果操作数还不可用，一直监听 CDB 直到可用</li><li>可用时候上到功能部件执行</li><li>如果多条指令同时可以执行，任选一条</li><li>如果是访存指令，按照程序顺序执行，并且把地址传到 load/store buffer 里等访存部件可用</li><li>访存指令可以简化按照程序顺序计算访存地址，但 <code>load</code> 之间是可以乱序的</li></ol></li><li>write result：在 CDB 上广播结果，写寄存器，如果是<code>store</code>指令，把地址和值写到 store buffer 中，等访存部件可用</li></ol><p><img loading=lazy src=/assets/img/tomasuloctrl.png alt="tomasulo ctrl"></p><p>Tomasulo 模式需要高速的集成的 cache 来保存大量消息，需要复杂的控制逻辑，需要高速高带宽的 CDB（多条 CDB 能提高带宽，但一致性需要解决）。Tomasulo 模式适合于多级 cache 的体系结构，因为可以掩盖不可控的 cache 延迟。对于程序员和编译器优化更友好。</p><h4 id=硬件预测>硬件预测<a hidden class=anchor aria-hidden=true href=#硬件预测>¶</a></h4><p>为了应对 control hazard，虽然有<a href=#%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B>分支预测技术</a>，分支指令过于频繁，或者是多发射处理器一次应对很多条指令，因此需要引入硬件预测。处理器执行犹如分支预测一直成功一样。</p><blockquote><p>reorder buffer</p><p>ROB。在执行完成和 commit 之间缓存结果</p><ol><li>指令类型</li><li>目标地址</li><li>值</li><li>Ready</li></ol></blockquote><ol><li>issue：从指令队列有序发射，只要 ROB 和保留站空</li><li>exectue：等 CDB 直到操作数全部就绪</li><li>write result：把结果暂存进 ROB</li><li>commit：有序提交<ol><li>把结果写到寄存器文件</li><li>实际进行<code>store</code>的访存</li><li>分支预测错误的 ROB 项清空</li></ol></li></ol><p><img loading=lazy src=/assets/img/dynspeculation.png alt="Dyn Speculation"></p><p>由于有序 commit，而改写寄存器和内存的值只在 commit 时候实现。因此可以保证只有在指令确定下来时候才实际更改机器状态。而且这也可以保证精确异常。而<code>load</code>的安全通过，1）在地址和某条 ROB 中地址重合时候不执行；2）按程序顺序计算访存地址来保证。</p><p>预测可能会导致出现本来不出现的异常和 cache miss。一般的，为了性能，预测阶段只会处理高级别 cache miss，其他的异常都等到指令确定性时候才触发。特别是比如权限的异常（不必要的终止，meltdown 漏洞等）。对于结构性较差的程序（比如数据库查询），预测执行可能会遇到大量嵌套的跳转。出于能耗和复杂度，一般不会对多分支多做优化。对于访存还可以通过 Address aliasing prediction，进一步发掘指令级并行度。</p><blockquote><p>Address aliasing prediction</p><p>预测访存地址是否冲突，从而允许访存相对乱序执行。相对简单，可以用简单的预测器实现</p></blockquote><blockquote><p>value prediction</p><p>预测指令的结果，进一步消除数据流之间的限制关系。过于复杂，目前没有实用性</p></blockquote><p>另一种方法是不使用 ROB，而是实际实现大量物理寄存器（对比 ISA 规定的逻辑寄存器，architectural register），使用 renaming map 管理寄存器重命名。只需要保证逻辑寄存器有关操作的正确，实际对应关系一直变动是不重要的。</p><h3 id=多发射>多发射<a hidden class=anchor aria-hidden=true href=#多发射>¶</a></h3><table><thead><tr><th>名称</th><th>发射结构</th><th>Hazard 检测</th><th>调度策略</th><th>特点</th><th>例子</th></tr></thead><tbody><tr><td>静态超标量</td><td>动态</td><td>硬件检测</td><td>静态调度</td><td>顺序执行</td><td>嵌入式芯片，如 MIPS，ARM，包括 Cortex-A53</td></tr><tr><td>动态超标量</td><td>动态</td><td>硬件检测</td><td>动态调度</td><td>乱序执行，不带推断</td><td>现在不存在</td></tr><tr><td>推断超标量</td><td>动态</td><td>硬件检测</td><td>动态调度</td><td>带推断的乱序执行</td><td>Intel Core i3, i5, i7; AMD Phenom；IBM Power</td></tr><tr><td>VLIW/LIW</td><td>静态</td><td>主要靠软件</td><td>静态调度</td><td>靠编译器检测和隐式提示 hazard</td><td>信号处理器，如 TI C6x</td></tr><tr><td>EPIC</td><td>大多数静态</td><td>主要靠软件</td><td>大多数静态调度</td><td>靠编译器检测和显式提示 hazard</td><td>Itanium</td></tr></tbody></table><ol><li>半周期发射指令。缺乏拓展性，只适用于双发射</li><li>在一个发射周期内，检查所有指令间的和与已发射指令的依赖关系。控制逻辑复杂</li></ol><p>多发射的处理器需要更好的取指部件，保证指令来源不成为瓶颈。常见的对取指部件优化有：</p><ol><li>在取指时候集成 <a href=#%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B>分支预测</a></li><li>预取指令</li><li>提供取来的指令的缓存</li></ol><h4 id=vliw>VLIW<a hidden class=anchor aria-hidden=true href=#vliw>¶</a></h4><blockquote><p>VLIW</p><p>very long instruction word。超长指令字。一条打包不同功能的指令</p></blockquote><h3 id=分支预测>分支预测<a hidden class=anchor aria-hidden=true href=#分支预测>¶</a></h3><p>在跳转指令到 EX 之前就猜测出跳转目标，就可以减少因为跳转带来的停顿。如果错误预测则需要清空流水线。</p><p>现实中的分支预测器极其影响性能。因此商业处理器的分支预测策略消息很少。</p><blockquote><p>Branch-Target Buffer</p><p>缓存历史的分支指令 PC 和 taken 对应预测目标的 PC。减少 PC 计算，下个周期直接取分支部位指令。如果分支预测正确，可以完全不停顿</p></blockquote><blockquote><p>branch folding</p><p>对于无条件跳转，可以给 Branch-Target Buffer 加一位 bit 提示，这样不再需要预测</p></blockquote><p>程序中存在跳转地址不固定的跳转指令，比如多处调用同一个函数，函数的返回地址就会变化。可以使用一个小的函数调用栈 cache，优化函数返回的跳转。</p><h4 id=静态预测>静态预测<a hidden class=anchor aria-hidden=true href=#静态预测>¶</a></h4><p>使用编译期信息进行分支预测。不同程序对于 taken 的概率对 50%有明显的偏移</p><h4 id=2-bitn-bit>2-bit/n-bit<a hidden class=anchor aria-hidden=true href=#2-bitn-bit>¶</a></h4><blockquote><p>branch-prediction buffer/branch history table</p><p>低位指令地址+预测器，如最简单的 1-bit 是否选择分支</p></blockquote><p>1-bit 的预测器可以扩展到 2-bit 状态机，防止偶发的 taken 变化造成 2 次错误预测。若为 n-bit，大于等于 $\frac{2^n-1}{2}$ 取 taken，反之 not taken。二者性能差异不大</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>   11 -NT-&gt; 10
</span></span><span class=line><span class=cl>   |        |
</span></span><span class=line><span class=cl>   T        NT
</span></span><span class=line><span class=cl>   |        |
</span></span><span class=line><span class=cl>   01 &lt;-T-- 00
</span></span></code></pre></td></tr></table></div></div><h4 id=mn预测器>(m,n)预测器<a hidden class=anchor aria-hidden=true href=#mn预测器>¶</a></h4><p>$$\text{bits used}=2^m\times n \times \text{Number of prediction entries selected by the branch address}$$</p><p>一个 m 位移位寄存器记录全局历史，当前跳转的前 m 个实际分支行为历史，每一位用来记录该分支是否实际被执行，1 对应实际执行，0 对应实际未执行。 $2^m$ 的可能性分别对应 $2^m$ 个 n-bit 简单预测器。因此，2-bit 相当于(0,2)预测器</p><h4 id=g-share-预测器>g-share 预测器<a hidden class=anchor aria-hidden=true href=#g-share-预测器>¶</a></h4><p>把分支历史和分支地址异或（类似于 hash 的功效）索引一个 2-bit 预测器</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-plaintext data-lang=plaintext><span class=line><span class=cl>   10-bit shift regester
</span></span><span class=line><span class=cl>|-[branch history]
</span></span><span class=line><span class=cl>|
</span></span><span class=line><span class=cl>|   10-bit
</span></span><span class=line><span class=cl>|-[branch address]
</span></span><span class=line><span class=cl>|
</span></span><span class=line><span class=cl>|-[XOR]- 2^10*[2-bit predictor]-&gt;
</span></span></code></pre></td></tr></table></div></div><h4 id=tournament锦标赛预测器>Tournament（锦标赛）预测器<a hidden class=anchor aria-hidden=true href=#tournament锦标赛预测器>¶</a></h4><p>结合局部 local 和全局 global 的 2-bit 预测器，并使用 branch address 选择 local/global 预测器。注意，预测错误时需要同时更新选择器和预测器。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-plaintext data-lang=plaintext><span class=line><span class=cl>   branch history
</span></span><span class=line><span class=cl>|-[2-bit global predictors]
</span></span><span class=line><span class=cl>|
</span></span><span class=line><span class=cl>|   branch address
</span></span><span class=line><span class=cl>|-[local predictors]
</span></span><span class=line><span class=cl>|
</span></span><span class=line><span class=cl>|-[MUX]-&gt;
</span></span><span class=line><span class=cl>    |
</span></span><span class=line><span class=cl>    | branch address
</span></span><span class=line><span class=cl>[2-bit selector]
</span></span></code></pre></td></tr></table></div></div><h4 id=tagged-hybridtage-预测器>Tagged Hybrid/TAGE 预测器<a hidden class=anchor aria-hidden=true href=#tagged-hybridtage-预测器>¶</a></h4><p><img loading=lazy src=/assets/img/taggedhybrid.png alt="TAGE 预测器"></p><p>使用不同历史记录长度的预测器$P(0),P(1)$ 。$P(i)$ 使用<code>PC</code>的一部分和（用移位寄存器记录）的最近 i 条分支历史的 hash 结果索引，包括 2-bit 预测器（实际中 3-bit 更好一点）+ 4-8bit 的 tag。<code>PC</code>和 tag 比较（$P(0)$不比较，作为默认使用预测器），决定使用本级的预测器还是上一级结果。</p><p>预测器可以包含一个 bit 用来表示该级是否最近使用过，并以此决定刷新频率。预测器内容的初始化有多种方式，而且对于短的程序，初始化的性能表现很重要。</p><ol><li>随机初始化</li><li>使用 valid bit 标记尚未初始化的条目</li><li>使用指令自带的偏向的 hint 初始化（如果不做动态预测器，那处理器就会使用 hint 作为预测</li><li>向后跳转指令可能用于循环，因此初始化为 taken</li></ol><h3 id=多周期指令>多周期指令<a hidden class=anchor aria-hidden=true href=#多周期指令>¶</a></h3><p>比如浮点运算对比整数 ALU 运算慢很多。如果希望浮点指令运算和整数指令运算都能在一个周期内完成，需要极大降低频率而损害性能。一般有额外的浮点功能部件：</p><ol><li>整数的 ALU，load，store，branch 功能部件</li><li>浮点数和整数乘法器</li><li>浮点加法器</li><li>浮点和整数除法器</li></ol><p>多周期指令会带来额外的复杂度。可以通过分离整数寄存器和浮点数寄存器简化依赖检测（只有浮点数 load-store 和浮点寄存器移动可能出现依赖）和减少 structural hazard （端口自然分离）发生。</p><ol><li>structural hazard：<ol><li>除法器不能完美流水化（额外除法器占晶体管资源）</li><li>多指令同时写回对寄存器文件写端口<ol><li>在 ID 阶段检测冲突并引入 stall，保持只在 ID 检测 interlock 和停止发射指令</li><li>在进入 MEM、WB 之前暂停指令，一般选择长周期指令优先（减少可能的 RAW），检测冲突更容易，但是流水线控制不好做</li></ol></li></ol></li><li>多周期要求多种中间寄存器</li><li>不同周期指令之间执行用时不一而 WAW（WAR 不可能，因为只有在 ID 阶段才读寄存器，ID 阶段进入是有序的）<ol><li>如果两条指令之间出现异常，连续写同一寄存器的 WAW 就会暴露出来。</li><li>可以 stall 顺序在后的指令</li><li>可以不执行前一条指令的写寄存器（注意精确异常的要求）</li></ol></li><li>不同周期指令的 out-of-order completion 对于精确异常的要求<ol><li>放弃精确异常/两种工作模式：早期机器和科学计算机器，但不符合 ieee 标准</li><li>缓存结果，有序提交（类似乱序处理器），可能空间占用大，而且<a href=#%E5%89%8D%E9%80%92>前递</a>复杂<ol><li>history file，记录历史值来回滚</li><li>future file，记录新值来更新</li></ol></li><li>不精确异常+回溯信息：异常恢复后模拟之前没完成指令的执行效果，适合简单处理器，整数指令一定执行完，只需考虑少数重叠的浮点指令</li><li>stall 直到肯定不出现不精确的异常</li></ol></li><li>长延迟对 RAW 有影响</li></ol><h3 id=中断异常>中断/异常<a hidden class=anchor aria-hidden=true href=#中断异常>¶</a></h3><blockquote><p>precise exception</p><p>精确异常：异常之前的指令都生效，异常之后的指令都没生效（执行到一半就要回滚已经产生的影响）</p></blockquote><p>精确异常符合程序员和编程语言的直觉，但一般会有一些困难。有可能处理器提供高性能计算模式而异常不精确的工作模式。但一般来说，page 相关异常和 ieee 整数运算异常一般都会被精确处理。</p><ol><li>指令中间状态需要回滚</li><li>指令执行中修改内存：异常时候保存工作寄存器，之后重新开始</li><li>隐式的修改状态寄存器：如同追踪寄存器依赖一样追踪潜在的 data hazard</li><li>长指令（如浮点运算指令，参见<a href=#%E5%A4%9A%E5%91%A8%E6%9C%9F%E6%8C%87%E4%BB%A4>多周期指令</a> ）</li></ol><table><thead><tr><th>Exception Type</th><th>Synchronous（和具体代码、数据有关） vs Asynchronous</th><th>User Request vs Coerced</th><th>User Maskable vs Nonmaskable</th><th>within（指令本身引发，需要重启指令） vs between Instructions</th><th>Resume vs Terminate</th></tr></thead><tbody><tr><td>I/O device request</td><td>Asynchronous</td><td>Coerced</td><td>Nonmaskable</td><td>Between</td><td>Resume</td></tr><tr><td>Invoke operating system</td><td>Synchronous</td><td>User request</td><td>Nonmaskable</td><td>Between</td><td>Resume</td></tr><tr><td>Tracing instruction execution</td><td>Synchronous</td><td>User request</td><td>User maskable</td><td>Between</td><td>Resume</td></tr><tr><td>Breakpoint</td><td>Synchronous</td><td>User request</td><td>User maskable</td><td>Between</td><td>Resume</td></tr><tr><td>Integer arithmetic overflow</td><td>Synchronous</td><td>Coerced</td><td>User maskable</td><td>Within</td><td>Resume</td></tr><tr><td>Floating-point arithmetic overflow or underflow</td><td>Synchronous</td><td>Coerced</td><td>User maskable</td><td>Within</td><td>Resume</td></tr><tr><td>Page fault</td><td>Synchronous</td><td>Coerced</td><td>Nonmaskable</td><td>Within</td><td>Resume</td></tr><tr><td>Misaligned memory accesses</td><td>Synchronous</td><td>Coerced</td><td>User maskable</td><td>Within</td><td>Resume</td></tr><tr><td>Memory protection violations</td><td>Synchronous</td><td>Coerced</td><td>Nonmaskable</td><td>Within</td><td>Resume</td></tr><tr><td>Using undefined instructions</td><td>Synchronous</td><td>Coerced</td><td>Nonmaskable</td><td>Within</td><td>Terminate</td></tr><tr><td>Hardware malfunctions</td><td>Asynchronous</td><td>Coerced</td><td>Nonmaskable</td><td>Within</td><td>Terminate</td></tr><tr><td>Power failure</td><td>Asynchronous</td><td>Coerced</td><td>Nonmaskable</td><td>Within</td><td>Terminate</td></tr></tbody></table><h3 id=pitfall-1>Pitfall<a hidden class=anchor aria-hidden=true href=#pitfall-1>¶</a></h3><ol><li>未预料的执行顺序会导致未预料的冲突<ul><li>即使是顺序处理器，浮点指令周期不同，两条指令之间出现异常，连续写同一寄存器而有可能产生 WAW</li></ul></li><li>过度设计的流水线会影响整个处理器设计，可能损害性价比<ul><li>VAX 系列，流水过深过于复杂导致主频低，而且消耗大量晶体管资源</li></ul></li><li>使用优化等级低的代码衡量处理器调度能力<ul><li>现实中代码一般都是<code>-O2</code>优化的；未优化代码存在大量冗余，不能充分考验处理器的硬件调度能力</li></ul></li><li>有时候加面积+不那么智能也很好<ul><li>把做复杂逻辑的晶体管面积直接做成 cache，根本上减少 cache 的延迟</li></ul></li><li>有时候更聪明更好<ul><li>高效的分支预测很重要，更低的错误率意味更少的清空流水线</li><li>对比<a href=#g-share-%E9%A2%84%E6%B5%8B%E5%99%A8>简单的 g-share 预测器</a>，更好的算法记录 tags，可以避免混淆不同地方的分支预测结果</li></ul></li><li>不存在永远可待挖掘的 ILP 的潜力<ul><li>即使采用非常理想的配置，现实中的程序（特别是整数程序）能并行的也是有限的</li></ul></li></ol><h3 id=fallacy-1>Fallacy<a hidden class=anchor aria-hidden=true href=#fallacy-1>¶</a></h3><ol><li>对于同一套指令集的不同版本，容易预测其性能和能耗<ul><li>Intel 的 i7 920 和 Atom 230 对比实验，性能差 4 倍，功耗差 10 倍</li><li>带推断的动态乱序执行有利于性能，但会极大提高功耗</li></ul></li><li>更低的 CPI，更快</li><li>更高的时钟频率，更快<ul><li>CPI 和时钟频率乘积共同决定性能，偏废会导致短板效应。</li></ul></li></ol><h2 id=ch-4-data-level-parallelism-in-vector-simd-and-gpu-architectures>ch 4 Data-Level Parallelism in Vector, SIMD, and GPU Architectures<a hidden class=anchor aria-hidden=true href=#ch-4-data-level-parallelism-in-vector-simd-and-gpu-architectures>¶</a></h2><blockquote><p>SIMD</p><p>single instruction multiple data</p></blockquote><blockquote><p>DLP</p><p>data level parallelism</p></blockquote><h3 id=roofline-model>Roofline-Model<a hidden class=anchor aria-hidden=true href=#roofline-model>¶</a></h3><p>可以定义计算强度，用来衡量程序内计算部分的占比。只有计算强度高的程序，才更容易被 SIMD/GPU 等加速</p><blockquote><p>arithmetric intensity</p><p>每 byte 内存访问对应的浮点运算次数。可用于预测 vector 支持对程序性能的提升</p></blockquote><p>给定的系统，不同计算强度的程序被不同因素限制住。计算强度低的程序，访存多而计算少，内存带宽跟不上，被带宽限制；计算强度高的程序，计算多而访存少，被浮点部件性能限制。因此，表现到图上就是 roofline 形状：随着计算强度增加，程序的 $\text{GFLOP/s}$ 提升；提升到了浮点性能极限时候，再改变计算强度，能实现的 $\text{GFLOP/s}$ 也是一条平行线。</p><p>$$
\begin{aligned}
\text{Attainable GFLOP/s}=\min( &\text{Peak Memory BW}\times\text{Arithmetic Intensity}, \\
& \text{Peak Floating-Point Perf})
\end{aligned}
$$</p><h3 id=向量架构>向量架构<a hidden class=anchor aria-hidden=true href=#向量架构>¶</a></h3><ol><li>向量寄存器：长的寄存器（eg，RV64V，64bit），一次存一个向量，支持不同数据类型（<code>i8,i16,i32,i64,f16,f32,f64</code>）</li><li>向量功能部件</li><li>向量访存部件</li><li>辅助的标量寄存器</li></ol><blockquote><p>dynamic register typing</p><p>每个向量寄存器配置不同的数据类型和长度，而不是在指令中区分</p><ol><li>简化向量指令的实现</li><li>允许关闭不用的寄存器，扩展使用的寄存器位数</li><li>不同类型的操作数之间</li></ol></blockquote><blockquote><p>convoy</p><p>一组可以同时执行的向量指令（必须不存在 structural hazard）。其用时为 chime</p></blockquote><p>可以简化的认为，通过 convoy 数目表征向量程序用时。同一个 convoy 里面可以出现 RAW，因为向量的一部分元素在一个部件完成后可以直接前递到其他部件。一个 convoy 会处理多个元素，仍然有很高的并行度。</p><ul><li>RV64V 只允许位置相同的元素进行向量间运算，因此多条流水线可以并行处理各个元素</li><li><code>vl</code>寄存器用于标记长度（必然 $\le \rm{mvl}$，maximum vector length）。可以在运行时动态指定（strip mining），只对<code>vl</code>长度进行处理</li><li><blockquote><p>vector-mask control</p><p>用一个 mask 条件执行来完成分支</p></blockquote></li><li>向量功能部件要求更好的访存<ol><li>每个周期允许多个访存</li><li>支持不连续的访存</li><li>允许多核间共享内存</li></ol></li><li><blockquote><p>stride</p><p>对于没有分块缓存的，先按 stride(nonunit strides)预读入向量，将空间不相邻元素转换为逻辑相邻。由于跨 stride 步长加载元素，有可能短时间 GCD 访问同一内存单元，造成阻塞，条件如下$\frac{\text{numbers of banks}}{\text{GCD(stride, number of banks)}}&lt;\text{bank busy time}$</p></blockquote></li><li><blockquote><p>gather-scatter</p><p>对索引访存（eg 稀疏矩阵）进行优化，需要额外的索引寄存器，比起其他访存更慢</p></blockquote></li></ul><h3 id=面向多媒体的-simd-扩展>面向多媒体的 SIMD 扩展<a hidden class=anchor aria-hidden=true href=#面向多媒体的-simd-扩展>¶</a></h3><p>一般不支持 mask registers、gather-scatter 以及 stride 等向量化高级优化手段，一般要求固定的向量长度和类型（从而导致指令集膨胀，每种数据类型对应一条指令），因此向量化程序不容易编写，编译器不容易优化，一般只针对专门的多媒体库（音视频的数据表示一般不需要全长度）或者是手写内嵌汇编。实例有 intel 的 MMX，SSE，AVX（开始支持高级操作）等。SIMD 扩展可能带来历史兼容性的问题。</p><ol><li>再增加基本运算单元花销小（模式简单，MMX 用原先的 64bit 浮点寄存器支持$8\times 8$-bit 或$4\times 16$-bit 的操作），容易支持</li><li>比起专门的 vector 架构，添加 SIMD 支持给处理器带来额外的状态，需要在上下文切换时候保存</li><li>vector architecture 需要内存带宽支持发挥最大性能</li><li>一般的 SIMD 扩展要求内存对齐访问，对于虚拟内存实现方便，不会跨页 page fault</li><li>向量长度定长，便于加入新的向量操作来支持新的多媒体应用需求</li></ol><h3 id=gpu>GPU<a hidden class=anchor aria-hidden=true href=#gpu>¶</a></h3><h4 id=cuda>CUDA<a hidden class=anchor aria-hidden=true href=#cuda>¶</a></h4><p>Nvidia 为其 GPU 提供了兼容 C/C++的编程解决方案，CUDA。</p><ul><li>GPU 上运行的函数标识 <code>__device__</code> <code>__global__</code> ；CPU 上运行的函数标识<code> __host__</code></li><li>CUDA 变量 <code>__device__</code> ，分配在 GPU Memory 上，所有的 multithreaded SIMD Processors 可访问</li><li>函数调用形式为 <code>name&lt;&lt;&lt;dimGrid, dimBlock>>> (… parameter list…)</code><ul><li><code>dimGrid</code>规定 thread block 数目，用<code>blockIdx</code>索引</li><li><code>dimBlock</code>规定一个 block 内 thread 数目，用<code>threadIdx</code>索引</li></ul></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=c1>// Invoke DAXPY
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>daxpy</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c1>// DAXPY in C
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>void</span> <span class=nf>daxpy</span><span class=p>(</span><span class=kt>int</span> <span class=n>n</span><span class=p>,</span> <span class=kt>double</span> <span class=n>a</span><span class=p>,</span> <span class=kt>double</span> <span class=o>*</span><span class=n>x</span><span class=p>,</span> <span class=kt>double</span> <span class=o>*</span><span class=n>y</span><span class=p>){</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=o>++</span><span class=n>i</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=o>*</span><span class=n>x</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// Invoke DAXPY with 256 threads per Thread Block
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>__host__</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>nblocks</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span><span class=o>+</span> <span class=mi>255</span><span class=p>)</span> <span class=o>/</span> <span class=mi>256</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>daxpy</span><span class=o>&lt;&lt;&lt;</span><span class=n>nblocks</span><span class=p>,</span> <span class=mi>256</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// DAXPY in CUDA
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>__global__</span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>daxpy</span><span class=p>(</span><span class=kt>int</span> <span class=n>n</span><span class=p>,</span> <span class=kt>double</span> <span class=n>a</span><span class=p>,</span> <span class=kt>double</span> <span class=o>*</span><span class=n>x</span><span class=p>,</span> <span class=kt>double</span> <span class=o>*</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=o>*</span><span class=n>x</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>CUDA 会编译成 PTX（Parallel Thread Execution）指令集，有如下格式</p><pre tabindex=0><code class=language-x86asm data-lang=x86asm>opcode.type d, a, b, c;
</code></pre><ul><li>type 类型，bits/整形/浮点</li><li>d 目标</li><li>a，b，c 源</li></ul><p>原先的<code>DAXPY</code>对应的汇编如下</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-asm data-lang=asm><span class=line><span class=cl><span class=nf>shl.u32</span> <span class=no>R8</span><span class=p>,</span> <span class=no>blockIdx</span><span class=p>,</span> <span class=mi>8</span> <span class=c>; Thread Block ID * Block size ;(256 or 28)
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>add.u32</span> <span class=no>R8</span><span class=p>,</span> <span class=no>R8</span><span class=p>,</span> <span class=no>threadIdx</span> <span class=c>; R8 = i = my CUDA Thread ID
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>shl.u32</span> <span class=no>R8</span><span class=p>,</span> <span class=no>R8</span><span class=p>,</span> <span class=mi>3</span> <span class=c>; byte offset
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>ld.global.f64</span> <span class=no>RD0</span><span class=p>,</span> <span class=p>[</span><span class=no>X</span><span class=err>+</span><span class=no>R8</span><span class=p>]</span><span class=c>; RD0 = X[i]
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>ld.global.f64</span> <span class=no>RD2</span><span class=p>,</span> <span class=p>[</span><span class=no>Y</span><span class=err>+</span><span class=no>R8</span><span class=p>]</span><span class=c>; RD2 = Y[i]
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>mul.f64</span> <span class=no>RD0</span><span class=p>,</span> <span class=no>RD0</span><span class=p>,</span> <span class=no>RD4</span> <span class=c>; Product in RD0 = RD0 * RD4 (scalar a)
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>add.f64</span> <span class=no>RD0</span><span class=p>,</span> <span class=no>RD0</span><span class=p>,</span> <span class=no>RD2</span> <span class=c>; Sum in RD0 = RD0 + RD2 (Y[i])
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>st.global.f64</span> <span class=p>[</span><span class=no>Y</span><span class=err>+</span><span class=no>R8</span><span class=p>],</span> <span class=no>RD0</span><span class=c>; Y[i] = sum (X[i]*a + Y[i])
</span></span></span></code></pre></td></tr></table></div></div><p>PTX 的所有访存模式都是 gather-scatter。为了加速顺序访问，要求访存遵守 Address Coalescing 的规则，以便合并为块访存。</p><p>GPU 使用 mask(编译器和硬件隐性设置，而不是显式有指令设置)和 branch synchronization stack（线程私有，每个条目一个标识符，一个目标地址，一个 mask）显式执行分支。预先算出 mask，压栈，使用 IF-THEN-ELSE 模式执行（要么执行 THEN 要么执行分支 ELSE）。除非全 0/1，会跳过其中一个分支，否则分支永远带来额外开销。因为 GPU Thread 之间强依赖，同一个 Thread Block 内的 lane 要么执行相同的指令，要么闲置，不能像操作系统线程那样分别执行。该机制同样适用于向量长度不是整数倍情况。</p><p>对于以下代码，对应 PTX 汇编</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>if</span> <span class=p>(</span><span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>){</span>
</span></span><span class=line><span class=cl>   <span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>Y</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>Z</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-asm data-lang=asm><span class=line><span class=cl><span class=nf>ld.global.f64</span> <span class=no>RD0</span><span class=p>,</span> <span class=p>[</span><span class=no>X</span><span class=err>+</span><span class=no>R8</span><span class=p>]</span> <span class=c>; RD0 = X[i]
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>setp.neq.s32</span> <span class=no>P1</span><span class=p>,</span> <span class=no>RD0</span><span class=p>,</span> <span class=c>#0 ;P1 is predicate reg 1
</span></span></span><span class=line><span class=cl><span class=c></span><span class=err>@</span><span class=p>!</span><span class=no>P1</span><span class=p>,</span> <span class=no>bra</span> <span class=no>ELSE1</span><span class=p>,</span> <span class=p>*</span><span class=no>Push</span> <span class=c>; Push old mask, set new
</span></span></span><span class=line><span class=cl><span class=c></span>						<span class=c>; mask bits if P1 false, go to ELSE1
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>ld.global.f64</span> <span class=no>RD2</span><span class=p>,</span> <span class=p>[</span><span class=no>Y</span><span class=err>+</span><span class=no>R8</span><span class=p>]</span><span class=c>; RD2 = Y[i]
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>sub.f64</span> <span class=no>RD0</span><span class=p>,</span> <span class=no>RD0</span><span class=p>,</span> <span class=no>RD2</span><span class=c>; Difference in RD0
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>st.global.f64</span> <span class=p>[</span><span class=no>X</span><span class=err>+</span><span class=no>R8</span><span class=p>],</span> <span class=no>RD0</span><span class=c>; X[i] = RD0
</span></span></span><span class=line><span class=cl><span class=c></span><span class=err>@</span><span class=no>P1</span><span class=p>,</span> <span class=no>bra</span> <span class=no>ENDIF1</span><span class=p>,</span> <span class=p>*</span><span class=no>Comp</span><span class=c>; complement mask bits
</span></span></span><span class=line><span class=cl><span class=c></span>						<span class=c>; if P1 true, go to ENDIF1
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>ELSE1</span><span class=p>:</span> <span class=no>ld.global.f64</span> <span class=no>RD0</span><span class=p>,</span> <span class=p>[</span><span class=no>Z</span><span class=err>+</span><span class=no>R8</span><span class=p>]</span> <span class=c>; RD0 = Z[i]
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>st.global.f64</span> <span class=p>[</span><span class=no>X</span><span class=err>+</span><span class=no>R8</span><span class=p>],</span> <span class=no>RD0</span> <span class=c>; X[i] = RD0
</span></span></span><span class=line><span class=cl><span class=c></span><span class=no>ENDIF1</span><span class=p>:</span><span class=err>&lt;</span><span class=no>next</span> <span class=no>instruction</span><span class=err>&gt;</span><span class=p>,</span> <span class=p>*</span><span class=no>Pop</span>
</span></span><span class=line><span class=cl><span class=c>; pop to restore old mask
</span></span></span></code></pre></td></tr></table></div></div><h4 id=层次结构>层次结构<a hidden class=anchor aria-hidden=true href=#层次结构>¶</a></h4><p>代码组织成 3 层：</p><ol><li>Grid：一段并行的任务</li><li>Thread Block：在一个处理器（Streaming Multiprocessor）上并行的代码段，共用 local memory 和一组寄存器（<strong>数目有限</strong>）</li><li>Thread：串行执行的代码段，寄存器<strong>有上限</strong>的从共用寄存器按需分配</li></ol><p>两层调度</p><ol><li>Thread Block Scheduler：把 Gird 或多个 Thread Block 在处理器之间调度</li><li>SIMD Thread Scheduler：单个 Thread Block 在处理器内调度，内部类似 SIMD 指令，彼此独立，可以使用 <a href=#scoreboard>scoreboard 乱序追踪指令</a>以掩盖访存延迟</li></ol><p>存储层次</p><ol><li>private memory：在片外 DRAM 上，thread 私有一小部分</li><li>local memory：片内的高带宽低延迟存储，对 multiprocessor 内私有，但如果多个 Thread Block 同时执行，不能在之间共享状态</li><li>GPU memory：片外 DRAM 上，host 能读写</li></ol><h4 id=对照>对照<a hidden class=anchor aria-hidden=true href=#对照>¶</a></h4><table><thead><tr><th>方面</th><th>vector architecture</th><th>GPU</th></tr></thead><tbody><tr><td>隐藏访存延迟</td><td>深流水线，不同流水级之间重叠执行</td><td>多 thread</td></tr><tr><td>分支</td><td>显式设置 mask</td><td>硬件和汇编器隐式设置 mask 和 stack</td></tr><tr><td>控制</td><td>专门的 control processor：调度、算标量、算地址</td><td>只有 scheduler，自己计算地址（之后 Address Coalescing）、算标量</td></tr><tr><td>标量计算</td><td>专门的 scalar 部分，片上网络连接</td><td>靠 CPU，PCIe 总线连接，开销更大</td></tr><tr><td>并行部件</td><td>lane 数目少，寄存器少</td><td>lane 很多，multiprocessor 也多，寄存器空间大</td></tr></tbody></table><table><thead><tr><th>More Descriptive Name used in this Book</th><th>Closest old term outside of GPUs</th><th>Official CUDA/ NVIDIA Term</th><th>Book Definition and OpenCL Terms</th><th>Official CUDA/NVIDIA Definition</th></tr></thead><tbody><tr><td>Vectorizable Loop</td><td>Vectorizable Loop</td><td>Grid</td><td>A vectorizable loop, executed on the GPU, made up of 1 or more “Thread Blocks” (or bodies of vectorized loop) that can execute in parallel.OpenCL name is “index range.”</td><td>A Grid is an array of Thread Blocks that can execute concurrently, equentially, or a mixture.</td></tr><tr><td>Body of Vectorized Loop</td><td>Body of a (Strip-Mined) Vectorized Loop</td><td>Thread Block</td><td>A vectorized loop executed on a “Streaming Multiprocessor” (multithreaded SIMD processor), made up of 1 or more “Warps” (or threads of SIMD instructions). These “Warps” (SIMD Threads) can communicate via “Shared Memory” (Local Memory). OpenCL calls a thread block a “work group.”</td><td>A Thread Block is an array of CUDA threads that execute concurrently together and can cooperate and communicate via Shared Memory and barrier synchronization. A Thread Block has a Thread Block ID within its Grid.</td></tr><tr><td>Sequence of SIMD Lane Operations</td><td>One iteration of a Scalar Loop</td><td>CUDA Thread</td><td>A vertical cut of a “Warp” (or thread of SIMD instructions) corresponding to one element executed by one “Thread Processor” (or SIMD lane). Result is stored depending on mask. OpenCL calls a CUDA thread a “work item.”</td><td>A CUDA Thread is a lightweight thread that executes a sequential program and can cooperate with other CUDA threads executing in the same Thread Block. A CUDA thread has a thread ID within its Thread Block.</td></tr><tr><td>A Thread of SIMD Instructions</td><td>Thread of Vector Instructions</td><td>Warp</td><td>A traditional thread, but it contains just SIMD instructions that are executed on a “Streaming Multiprocessor” (multithreaded SIMD processor). Results stored depending on a per element mask.</td><td>A Warp is a set of parallel CUDA Threads (e.g., 32) that execute the same instruction together in a multithreaded SIMT/SIMD processor.</td></tr><tr><td>SIMD Instruction</td><td>Vector Instruction</td><td>PTX Instruction</td><td>A single SIMD instruction executed across the “Thread Processors” (SIMD lanes).</td><td>A PTX instruction specifies an instruction executed by a CUDA Thread.</td></tr><tr><td>Multithreaded SIMD Processor</td><td>(Multithreaded) Vector Processor</td><td>Streaming Multiprocessor</td><td>Multithreaded SIMD processor that executes “Warps” (thread of SIMD instructions), independent of other SIMD processors. OpenCL calls it a “Compute Unit.” However, CUDA programmer writes program for one lane rather than for a “vector” of multiple SIMD lanes.</td><td>A Streaming Multiprocessor (SM) is a multithreaded SIMT/SIMD processor that executes Warps of CUDA Threads. A SIMT program specifies the execution of one CUDA thread, rather than a vector of multiple SIMD lanes.</td></tr><tr><td>Thread Block Scheduler</td><td>Scalar Processor</td><td>Giga Thread Engine</td><td>Assigns multiple “Thread Blocks” (or body of vectorized loop) to “Streaming Multiprocessors” (multithreaded SIMD processors).</td><td>Distributes and schedules Thread Blocks of a Grid to Streaming Multiprocessors as resources become available.</td></tr><tr><td>SIMD Thread Scheduler</td><td>Thread Scheduler in a Multithread CPU</td><td>Warp Scheduler</td><td>Hardware unit that schedules and issues “Warps” (threads of SIMD instructions) when they are ready to execute; includes a scoreboard to track “Warp” (SIMD thread) execution.</td><td>A Warp Scheduler in a Streaming Multiprocessor schedules Warps for execution when their next instruction is ready to execute.</td></tr><tr><td>SIMD Lane</td><td>Vector Lane</td><td>Thread Processor</td><td>Hardware SIMD Lane that executes the operations in a “Warp” (thread of SIMD instructions) on a single element. Results stored depending on mask. OpenCL calls it a “Processing Element.”</td><td>A Thread Processor is a datapath and register file portion of a Streaming Multiprocessor that executes operations for one or more lanes of a Warp.</td></tr><tr><td>GPU Memory</td><td>Main Memory</td><td>Global memory</td><td>DRAM memory accessible by all “Streaming Multiprocessors” (or multithreaded SIMD processors) in a GPU. OpenCL calls it “Global Memory.”</td><td>Global Memory is accessible by all CUDA Threads in any Thread Block in any Grid. Implemented as a region of DRAM, and may be cached.</td></tr><tr><td>Private Memory</td><td>Stack / Thread Local Storage(OS)</td><td>Local Memory</td><td>Portion of DRAM memory private to each “Thread Processor” (SIMD lane). OpenCL calls it “Private Memory.”</td><td>Private “thread-local” memory for a CUDA Thread. Implemented as a cached region of DRAM.</td></tr><tr><td>Local Memory</td><td>Local Memory</td><td>Shared Memory</td><td>Fast local SRAM for one “Streaming Multiprocessor” (multithreaded SIMD processor), unavailable to other Streaming Multiprocessors. OpenCL calls it “Local Memory.”</td><td>Fast SRAM memory shared by the CUDA Threads composing a Thread Block, and private to that Thread Block. Used for communication among CUDA Threads in a Thread Block at barrier synchronization points.</td></tr><tr><td>SIMD Lane Registers</td><td>Vector Lane Registers</td><td>Registers</td><td>Registers in a single “Thread Processor” (SIMD lane) allocated across full “Thread Block” (or body of vectorized loop).</td><td>Private registers for a CUDA Thread. Implemented as multithreaded register file for certain lanes of several warps for each thread processor.</td></tr></tbody></table><h3 id=loop-level-parallelism-改进>Loop-level parallelism 改进<a hidden class=anchor aria-hidden=true href=#loop-level-parallelism-改进>¶</a></h3><p>在源码（或者接近源码级别检测）</p><blockquote><p>loop-carried dependence</p><p>循环依赖于之前的结果</p></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=c1>//没有 loop-carried dependence
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>999</span><span class=p>;</span> <span class=n>i</span><span class=o>&gt;=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>){</span>
</span></span><span class=line><span class=cl>   <span class=n>x</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>s</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>//有 loop-carried dependence
</span></span></span><span class=line><span class=cl><span class=c1>// S1 S2 都有对自身的循环依赖（有自环，无法消除）
</span></span></span><span class=line><span class=cl><span class=c1>// S2 还有循环内对S1的依赖
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>&lt;</span><span class=mi>100</span><span class=p>;</span> <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=n>A</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>A</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>C</span><span class=p>[</span><span class=n>i</span><span class=p>];</span> <span class=cm>/* S1 */</span>
</span></span><span class=line><span class=cl>   <span class=n>B</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>B</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>A</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>];</span> <span class=cm>/* S2 */</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>//有 loop-carried dependence也可以改进
</span></span></span><span class=line><span class=cl><span class=c1>// S2 不是成环依赖 S1
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>&lt;</span><span class=mi>100</span><span class=p>;</span> <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=n>A</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>A</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>B</span><span class=p>[</span><span class=n>i</span><span class=p>];</span> <span class=cm>/* S1 */</span>
</span></span><span class=line><span class=cl>   <span class=n>B</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>C</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>D</span><span class=p>[</span><span class=n>i</span><span class=p>];</span> <span class=cm>/* S2 */</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 可以改成能并行的版本
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>A</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>A</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>B</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>&lt;</span><span class=mi>99</span><span class=p>;</span> <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=n>B</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>C</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>D</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>   <span class=n>A</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>A</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>B</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>B</span><span class=p>[</span><span class=mi>100</span><span class=p>]</span> <span class=o>=</span> <span class=n>C</span><span class=p>[</span><span class=mi>99</span><span class=p>]</span> <span class=o>+</span> <span class=n>D</span><span class=p>[</span><span class=mi>99</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 特殊的 recurrence 形式的循环依赖
</span></span></span><span class=line><span class=cl><span class=c1>// 一些架构/语言对 recurrence 有专门支持
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;</span><span class=mi>100</span><span class=p>;</span><span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=n>Y</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>Y</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>Y</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=依赖检测>依赖检测<a hidden class=anchor aria-hidden=true href=#依赖检测>¶</a></h4><blockquote><p>Affine</p><p>当一维数组的索引可以写成 $a\times i +b$的形式，当中$a,b$为常数，$i$为循环变量，索引可认为 affine。当多维数组中每一维的索引满足 affine，索引可认为 affine</p><p>一般的稀疏访问<code>x[y[i]]</code>，一般不是 affine 的</p></blockquote><p>对应 affine 的索引，同一个数组分别按照$a\times i +b$ 、 $c\times i+d$进行索引，$i\in [m,n]$时，有依赖关系</p><ol><li>两个索引$m\le j\le n,m\le k \le n$</li><li>存在$a\times j+b=c\times k+d$的访问</li></ol><p>可以简化的使用 GCD（最大公因数）法检测。只保证充分性；因为未考虑边界条件，所以不满足必要性。事实上，检测依赖属于 $\mathcal{NP}-Complete$ 问题</p><p>$$(d-b)\mod\rm{GCD}(c,a)=0$$</p><h4 id=另一种依赖消除>另一种依赖消除<a hidden class=anchor aria-hidden=true href=#另一种依赖消除>¶</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=c1>// 有循环依赖
</span></span></span><span class=line><span class=cl><span class=c1>// 具有 reduction 形式，有些语言/硬件有特殊支持
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>9999</span><span class=p>;</span> <span class=n>i</span><span class=o>&gt;=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=n>sum</span> <span class=o>=</span> <span class=n>sum</span> <span class=o>+</span> <span class=n>x</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>//改进为
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>9999</span><span class=p>;</span> <span class=n>i</span><span class=o>&gt;=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=n>sum</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>9999</span><span class=p>;</span> <span class=n>i</span><span class=o>&gt;=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=n>finalsum</span> <span class=o>=</span> <span class=n>finalsum</span> <span class=o>+</span> <span class=n>sum</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 假设10核，可以分摊到多核上处理
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>9999</span><span class=p>;</span> <span class=n>i</span><span class=o>&gt;=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>=</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=n>finalsum</span> <span class=o>=</span> <span class=n>finalsum</span> <span class=o>+</span> <span class=n>sum</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=fallacy-2>Fallacy<a hidden class=anchor aria-hidden=true href=#fallacy-2>¶</a></h3><ol><li>GPU 和 CPU 分离不好<ul><li>分离主内存和 GPU 内存有劣势（eg，需要专门的内存复制<code>cudaMemcpy()</code>）</li><li>PTX 指令集和硬件可以根据环境需求动态增减特性，而且不影响 CPU 端的体系结构</li><li>同时 GPU 端也和 CPU 端的体系结构变动解耦</li></ul></li><li>不给 vector architecture 提供足够的访存带宽<ul><li>记住<a href=#roofline-model>roofline 模型</a>，足够的内存带宽才能有足够数据喂饱计算能力</li></ul></li><li>如果 GPU 访存性能不好，无脑增加 thread 数目<ul><li>thread 之间需要能够访存融合，否则会导致单独的大量访存反而影响性能</li><li>thread 本身也需要足够好的访存局部性</li></ul></li></ol><h3 id=pitfall-2>Pitfall<a hidden class=anchor aria-hidden=true href=#pitfall-2>¶</a></h3><ol><li>忽略启动开销来对比 vector architecture 之间的峰值性能<ul><li>早期向量架构启动很慢，短向量（eg，$\le 100$）还不如直接用标量处理器</li></ul></li><li>只关注 vector architecture 的向量性能，不关注标量性能<ul><li>注意 Amdahl 定律，标量性能很有用（eg，strip mining，不满长的向量的下标索引）</li><li>增加 SIMD lane 数目同时，需要响应提升标量部分性能</li></ul></li></ol><h2 id=ch-a-instruction-set-principles>ch A Instruction Set Principles<a hidden class=anchor aria-hidden=true href=#ch-a-instruction-set-principles>¶</a></h2><h3 id=isa-特性>ISA 特性<a hidden class=anchor aria-hidden=true href=#isa-特性>¶</a></h3><p>对于 ISA 设计，其有如下一些考虑：</p><ol><li>指令集类型<ol><li>栈</li><li>累加器</li><li>寄存器-内存</li><li>寄存器-寄存器/load-store</li></ol></li><li>地址访问：对齐、不对齐</li><li>寻址模式<ol><li>立即数 <code>3</code></li><li>寄存器 <code>Regs[R4]</code></li><li>寄存器访存 <code>Mem[Regs[R4]]</code></li><li>寄存器+偏移访存 <code>Mem[Regs[R4]+10]</code></li><li>寄存器+寄存器访存 <code>Mem[Regs[R3]+Regs[R4]]</code></li><li>立即数访存 <code>Mem[1001]</code></li><li>PC 相关 <code>pc</code></li><li>寄存器间接访存 <code>Mem[Mem[Regs[R4]]]</code></li><li>自增自减 <code>Mem[Regs[R2]+=d]</code></li><li>寄存器+寄存器倍增访存 <code>Mem[Regs[R2]+Regs[R3]*d]</code></li></ol></li><li>操作数类型：<ol><li>整型 <code>u8,i8,u16,i16,u32,i32,u64,i64</code></li><li>浮点数<code>f32,f64</code></li><li>拓展浮点数 80 位</li></ol></li><li>指令类型<ol><li>运算和逻辑</li><li>访存</li><li>控制</li><li>系统特权有关</li><li>浮点数指令</li><li>decimal 指令</li><li>字符串指令</li><li>图像指令</li><li>SIMD</li></ol></li><li>控制流指令<ol><li>无条件跳转</li><li>条件转移</li><li>函数调用</li><li>函数 return</li></ol></li><li>ISA 编码：<ol><li>寄存器数目：对应编译器分配，解依赖，编码长度</li><li>定长，变长</li><li>寄存器编码位置固定/不固定</li></ol></li></ol><h3 id=编译器优化>编译器优化<a hidden class=anchor aria-hidden=true href=#编译器优化>¶</a></h3><table><thead><tr><th>编译器层次</th><th>依赖</th><th>功能</th></tr></thead><tbody><tr><td>front end per language</td><td>语言相关，和机器无关</td><td>语言翻译成通用 intermediate 形式</td></tr><tr><td>high-level optimizations</td><td>语言相关，基本和机器无关</td><td>eg，循环展开，函数内连</td></tr><tr><td>global optimizer</td><td>基本语言无关，和机器有关（寄存器数目和类型）</td><td>优化和寄存器分配</td></tr><tr><td>code generator</td><td>语言无关，机器相关</td><td>具体的机器特定优化和指令选择</td></tr></tbody></table><ol><li>寄存器数目$\ge 16$个以方便启发性的 group coloring 的寄存器分配算法（本质是个$\mathcal{NP}$问题，只有近似线性的启发式算法）</li><li>保证常见场景优化+罕见场景正确</li><li>操作，数据类型和寻址 3 者可以正交组合</li><li>提供 primitive 原语，而不是方案，防止过于适配高层语言</li><li>简化 trade-off 的选择</li><li>保证编译期常量能直接绑定到指令</li></ol><p>SIMD 指令基本上违背所有原则（vec 寄存器数目少，寻址模式过于简单，vec 类型不常见 etc.）。因此 SIMD 一般只有用在人工编写的底层库</p><h3 id=isa-统计和对应的-risc-v-设计>ISA 统计和对应的 RISC-V 设计<a hidden class=anchor aria-hidden=true href=#isa-统计和对应的-risc-v-设计>¶</a></h3><h3 id=fallacy-3>Fallacy<a hidden class=anchor aria-hidden=true href=#fallacy-3>¶</a></h3><ol><li>存在一个典型程序：不同程序对 ISA 的使用差异巨大</li><li>有缺陷的 ISA 不能成功（80x86）</li><li>存在完美的体系结构<ul><li>trade-off 永存</li><li>不同技术和时代强调目标不同</li></ul></li></ol><h3 id=pitfall-3>Pitfall<a hidden class=anchor aria-hidden=true href=#pitfall-3>¶</a></h3><ol><li>设计一个高层次指令来支持高层语言的结构<ul><li>semantic gap：过于复杂，功能过剩，或者是对于其他语言其约定有差异</li></ul></li><li>设计 ISA 时候不考虑编译器优化<ul><li>编译器优化等级对于体积优化和性能优化结果差异很大</li></ul></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://livypad.github.io/tags/%E6%95%99%E7%A8%8B/>教程</a></li><li><a href=https://livypad.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/>读书笔记</a></li></ul><nav class=paginav><a class=next href=https://livypad.github.io/post/2023-02-27-adalg/><span class=title>Next Page »</span><br><span>高级算法设计-课堂笔记（更新到第11次课）</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://livypad.github.io>zhh's blog</a></span><span style=display:inline-block;margin-left:1em>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
    <a href=https://github.com/reorx/hugo-PaperModX/ rel=noopener target=_blank>PaperModX</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script>
<script>(function(){const t=""=="1";if(t)return;let e=document.getElementById("theme-toggle");e.removeEventListener("click",toggleThemeListener),e.addEventListener("click",toggleThemeListener)})()</script><script>(function(){let e=document.getElementById("menu");e&&(e.scrollLeft=localStorage.getItem("menu-scroll-position"),e.onscroll=function(){localStorage.setItem("menu-scroll-position",e.scrollLeft)});const t=""=="1",n=""=="1";if(window.matchMedia("(prefers-reduced-motion: reduce)").matches||t||n)return;document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})})()</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>if(window.scrollListeners)for(const e of scrollListeners)window.removeEventListener("scroll",e);window.scrollListeners=[]</script><script src=/js/medium-zoom.min.js data-no-instant></script>
<script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){const r="1"=="1";if(!r)return;if(!document.querySelector(".toc")){console.log("no toc found, ignore toc scroll");return}const c=window.scrollListeners,n=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id]"),s="active";let e=n[0];o(e).classList.add(s);const a=()=>{const t=[];for(const e of n)if(l(e)<5)t.push(e);else break;t.length>0?newActiveHeading=t[t.length-1]:newActiveHeading=n[0],e!=newActiveHeading&&(o(e).classList.remove(s),e=newActiveHeading,o(e).classList.add(s))};let t=null;const i=()=>{t!==null&&clearTimeout(t),t=setTimeout(a,50)};window.addEventListener("scroll",i,!1),c.push(i);function o(e){const t=encodeURI(e.getAttribute("id")).toLowerCase();return document.querySelector(`.toc ul li a[href="#${t}"]`)}function l(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect();return t.top}})()</script></body></html>